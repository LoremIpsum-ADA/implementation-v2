{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa79cb0f",
   "metadata": {},
   "source": [
    "# Causal analysis pipeline — Endangered species in Asia\n",
    "\n",
    "**Notebook purpose:** Complete pipeline (data ingestion → preprocessing → causal analysis → robustness) for endangered species in Asia with natural disasters as treatment.\n",
    "\n",
    "**Geographic scope:** Asia bounding box [60°E, -10°S] to [150°E, 55°N]\n",
    "\n",
    "**Temporal scope:** 2000–2024 (annual aggregation)\n",
    "\n",
    "**Spatial resolution:** 0.1° grid (~11 km at equator)\n",
    "\n",
    "**Disaster types:** Wildfires, floods, cyclones/typhoons, earthquakes\n",
    "\n",
    "**Species:** IUCN threatened (CR, EN, VU) Aves, Mammalia, Reptilia, Amphibia with ≥50 GBIF occurrences\n",
    "\n",
    "**Estimators:** DiD (TWFE), Sun-Abraham (staggered), Synthetic Control, Bayesian hierarchical\n",
    "\n",
    "**Outputs:** Event-study plots, coefficient tables, maps, species summaries, robustness checks, processed panels\n",
    "\n",
    "**Structure:**\n",
    "1. Setup & dependencies\n",
    "2. Configuration\n",
    "3. Data ingestion: GBIF, EM-DAT, IUCN, hazard footprints\n",
    "4. Preprocessing & grid alignment\n",
    "5. Treatment construction\n",
    "6. Outcome construction\n",
    "7. Causal estimation (DiD, SCM, Bayesian)\n",
    "8. Robustness & falsification\n",
    "9. Visualization & reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee280f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set for endangered_asia_disaster_analysis\n",
      "Study region: [60.0, -10.0, 150.0, 55.0]\n",
      "Time range: (2000, 2024)\n",
      "Grid resolution: 0.1°\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\appoo\\AppData\\Local\\Temp\\ipykernel_15880\\2685328261.py:10: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  'notebook_generated_on': datetime.datetime.utcnow().isoformat() + 'Z',\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'study_name': 'endangered_asia_disaster_analysis',\n",
       " 'data_dir': WindowsPath('data'),\n",
       " 'results_dir': WindowsPath('results'),\n",
       " 'notebook_generated_on': '2025-11-06T06:48:54.186057Z',\n",
       " 'grid_resolution_deg': 0.1,\n",
       " 'region_bbox': [60.0, -10.0, 150.0, 55.0],\n",
       " 'time_unit': 'year',\n",
       " 'time_range': (2000, 2024),\n",
       " 'taxa': ['Aves', 'Mammalia', 'Reptilia', 'Amphibia'],\n",
       " 'target_status': ['CR', 'EN', 'VU'],\n",
       " 'min_occurrences': 50,\n",
       " 'disaster_types': ['wildfire', 'flood', 'cyclone', 'earthquake'],\n",
       " 'gbif_user': 'advaithmagic',\n",
       " 'gbif_password': 'gbifADA*1843',\n",
       " 'gbif_email': 'advaithsanilkumar@gmail.com',\n",
       " 'iucn_token': None,\n",
       " 'event_window': (-3, 5),\n",
       " 'clustering_var': 'grid_id',\n",
       " 'did_estimator': 'twfe',\n",
       " 'save_intermediate': True,\n",
       " 'figure_format': 'png',\n",
       " 'figure_dpi': 300}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Configuration — project parameters\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CONFIG = {\n",
    "    'study_name': 'endangered_asia_disaster_analysis',\n",
    "    'data_dir': Path('data'),  # relative to notebook location\n",
    "    'results_dir': Path('results'),\n",
    "    'notebook_generated_on': datetime.datetime.utcnow().isoformat() + 'Z',\n",
    "    \n",
    "    # Spatial parameters\n",
    "    'grid_resolution_deg': 0.1,\n",
    "    'region_bbox': [60.0, -10.0, 150.0, 55.0],  # [min_lon, min_lat, max_lon, max_lat]\n",
    "    \n",
    "    # Temporal parameters\n",
    "    'time_unit': 'year',\n",
    "    'time_range': (2000, 2024),\n",
    "    \n",
    "    # Species selection\n",
    "    'taxa': ['Aves', 'Mammalia', 'Reptilia', 'Amphibia'],\n",
    "    'target_status': ['CR', 'EN', 'VU'],\n",
    "    'min_occurrences': 50,  # minimum GBIF records per species\n",
    "    \n",
    "    # Disaster types\n",
    "    'disaster_types': ['wildfire', 'flood', 'cyclone', 'earthquake'],\n",
    "    \n",
    "    # API credentials (fill these in)\n",
    "    'gbif_user': None,  # GBIF username\n",
    "    'gbif_password': None,  # GBIF password\n",
    "    'gbif_email': None,\n",
    "    'iucn_token': None,  # IUCN API token (if using API)\n",
    "    \n",
    "    # Analysis parameters\n",
    "    'event_window': (-3, 5),  # years before/after for event study\n",
    "    'clustering_var': 'grid_id',  # for standard errors\n",
    "    'did_estimator': 'twfe',  # 'twfe', 'sun_abraham', or 'both'\n",
    "    \n",
    "    # Output formats\n",
    "    'save_intermediate': True,\n",
    "    'figure_format': 'png',\n",
    "    'figure_dpi': 300,\n",
    "}\n",
    "\n",
    "CONFIG['gbif_user'] = os.getenv('GBIF_USER')\n",
    "CONFIG['gbif_password'] = os.getenv('GBIF_PASSWORD')\n",
    "CONFIG['gbif_email'] = os.getenv('GBIF_EMAIL')\n",
    "CONFIG['iucn_token'] = os.getenv('IUCN_TOKEN')\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [CONFIG['data_dir'], CONFIG['results_dir']]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    (dir_path / 'raw').mkdir(exist_ok=True)\n",
    "    (dir_path / 'processed').mkdir(exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(CONFIG['results_dir'] / 'config.json', 'w') as f:\n",
    "    json.dump({k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()}, f, indent=2)\n",
    "\n",
    "print(f\"Configuration set for {CONFIG['study_name']}\")\n",
    "print(f\"Study region: {CONFIG['region_bbox']}\")\n",
    "print(f\"Time range: {CONFIG['time_range']}\")\n",
    "print(f\"Grid resolution: {CONFIG['grid_resolution_deg']}°\")\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd642b",
   "metadata": {},
   "source": [
    "## 3. Data Sources Overview\n",
    "\n",
    "**EM-DAT (CRED):** Global disaster records - requires registration at https://www.emdat.be/\n",
    "- Download disasters for Asia, 2000-2024\n",
    "- Filter by disaster types: wildfire, flood, storm, earthquake\n",
    "- Save as `data/raw/emdat_asia_2000_2024.csv`\n",
    "\n",
    "**GBIF:** Species occurrence data via API\n",
    "- Implemented below with bulk download workflow\n",
    "- Requires GBIF account (free): https://www.gbif.org/\n",
    "\n",
    "**IUCN Red List:** Species range maps\n",
    "- Download from https://www.iucnredlist.org/resources/spatial-data-download\n",
    "- Requires acceptance of terms\n",
    "- Save shapefiles to `data/raw/iucn/`\n",
    "\n",
    "**Hazard-specific footprints:**\n",
    "- MODIS/VIIRS burned area: https://modis-fire.umd.edu/\n",
    "- Copernicus EMS flood footprints: https://emergency.copernicus.eu/\n",
    "- USGS earthquake data: https://earthquake.usgs.gov/\n",
    "- NASA GPM IMERG precipitation: https://gpm.nasa.gov/\n",
    "\n",
    "**MODIS MCD12 land cover:** Annual global land cover at 500m\n",
    "- Download from https://lpdaac.usgs.gov/products/mcd12q1v006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fccb954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No IUCN token provided. Using curated example species list.\n",
      "For production: Set CONFIG['iucn_token'] with your API token\n",
      "\n",
      "Species to analyze: 13\n",
      "Taxonomic groups: {'Aves': 4, 'Mammalia': 4, 'Reptilia': 3, 'Amphibia': 2}\n",
      "Conservation status: {'EN': 6, 'CR': 5, 'VU': 2}\n",
      "\n",
      "Saved species list to data\\processed\\target_species.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxon</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Lophura edwardsi</td>\n",
       "      <td>CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Arborophila davidi</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Turdoides striata</td>\n",
       "      <td>VU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Carpococcyx renauldi</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Panthera tigris</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Elephas maximus</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Rhinoceros sondaicus</td>\n",
       "      <td>CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Pongo abelii</td>\n",
       "      <td>CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reptilia</td>\n",
       "      <td>Crocodylus siamensis</td>\n",
       "      <td>CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reptilia</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      taxon        scientificName status\n",
       "0      Aves      Lophura edwardsi     CR\n",
       "1      Aves    Arborophila davidi     EN\n",
       "2      Aves     Turdoides striata     VU\n",
       "3      Aves  Carpococcyx renauldi     EN\n",
       "4  Mammalia       Panthera tigris     EN\n",
       "5  Mammalia       Elephas maximus     EN\n",
       "6  Mammalia  Rhinoceros sondaicus     CR\n",
       "7  Mammalia          Pongo abelii     CR\n",
       "8  Reptilia  Crocodylus siamensis     CR\n",
       "9  Reptilia        Chelonia mydas     EN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4a. GBIF species list acquisition - get threatened species in Asia\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pygbif import species as gbif_species\n",
    "from pygbif import occurrences as gbif_occ\n",
    "import time\n",
    "\n",
    "def get_iucn_threatened_species_asia(taxa_list, status_list, bbox, iucn_token=None):\n",
    "    \"\"\"\n",
    "    Query IUCN Red List API for threatened species in Asia.\n",
    "    If no API token, returns a curated list of example species.\n",
    "    \n",
    "    For production: Get API token from https://apiv3.iucnredlist.org/api/v3/token\n",
    "    \"\"\"\n",
    "    species_list = []\n",
    "    \n",
    "    if iucn_token:\n",
    "        # Use IUCN API\n",
    "        base_url = \"https://apiv3.iucnredlist.org/api/v3\"\n",
    "        headers = {'token': iucn_token}\n",
    "        \n",
    "        for taxon in taxa_list:\n",
    "            for status in status_list:\n",
    "                try:\n",
    "                    # Get species by category and taxon\n",
    "                    url = f\"{base_url}/species/category/{status}\"\n",
    "                    response = requests.get(url, headers=headers, timeout=30)\n",
    "                    if response.status_code == 200:\n",
    "                        data = response.json()\n",
    "                        for sp in data.get('result', []):\n",
    "                            if sp.get('class_name', '').lower() == taxon.lower():\n",
    "                                species_list.append({\n",
    "                                    'taxon': taxon,\n",
    "                                    'scientificName': sp.get('scientific_name'),\n",
    "                                    'status': status,\n",
    "                                    'taxonid': sp.get('taxonid')\n",
    "                                })\n",
    "                    time.sleep(0.5)  # Rate limiting\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching {taxon} - {status}: {e}\")\n",
    "    else:\n",
    "        print(\"No IUCN token provided. Using curated example species list.\")\n",
    "        print(\"For production: Set CONFIG['iucn_token'] with your API token\")\n",
    "        \n",
    "        # Curated list of threatened species in Asia (examples from each taxonomic group)\n",
    "        species_list = [\n",
    "            # Aves (Birds)\n",
    "            {'taxon': 'Aves', 'scientificName': 'Lophura edwardsi', 'status': 'CR'},\n",
    "            {'taxon': 'Aves', 'scientificName': 'Arborophila davidi', 'status': 'EN'},\n",
    "            {'taxon': 'Aves', 'scientificName': 'Turdoides striata', 'status': 'VU'},\n",
    "            {'taxon': 'Aves', 'scientificName': 'Carpococcyx renauldi', 'status': 'EN'},\n",
    "            \n",
    "            # Mammalia (Mammals)\n",
    "            {'taxon': 'Mammalia', 'scientificName': 'Panthera tigris', 'status': 'EN'},\n",
    "            {'taxon': 'Mammalia', 'scientificName': 'Elephas maximus', 'status': 'EN'},\n",
    "            {'taxon': 'Mammalia', 'scientificName': 'Rhinoceros sondaicus', 'status': 'CR'},\n",
    "            {'taxon': 'Mammalia', 'scientificName': 'Pongo abelii', 'status': 'CR'},\n",
    "            \n",
    "            # Reptilia (Reptiles)\n",
    "            {'taxon': 'Reptilia', 'scientificName': 'Crocodylus siamensis', 'status': 'CR'},\n",
    "            {'taxon': 'Reptilia', 'scientificName': 'Chelonia mydas', 'status': 'EN'},\n",
    "            {'taxon': 'Reptilia', 'scientificName': 'Cuora trifasciata', 'status': 'CR'},\n",
    "            \n",
    "            # Amphibia (Amphibians)\n",
    "            {'taxon': 'Amphibia', 'scientificName': 'Ansonia latidisca', 'status': 'EN'},\n",
    "            {'taxon': 'Amphibia', 'scientificName': 'Rhacophorus catamitus', 'status': 'VU'},\n",
    "        ]\n",
    "    \n",
    "    return pd.DataFrame(species_list)\n",
    "\n",
    "# Get species list\n",
    "species_df = get_iucn_threatened_species_asia(\n",
    "    CONFIG['taxa'], \n",
    "    CONFIG['target_status'],\n",
    "    CONFIG['region_bbox'],\n",
    "    iucn_token=CONFIG['iucn_token']\n",
    ")\n",
    "\n",
    "print(f\"\\nSpecies to analyze: {len(species_df)}\")\n",
    "print(f\"Taxonomic groups: {species_df['taxon'].value_counts().to_dict()}\")\n",
    "print(f\"Conservation status: {species_df['status'].value_counts().to_dict()}\")\n",
    "\n",
    "# Save species list\n",
    "species_df.to_csv(CONFIG['data_dir'] / 'processed' / 'target_species.csv', index=False)\n",
    "print(f\"\\nSaved species list to {CONFIG['data_dir'] / 'processed' / 'target_species.csv'}\")\n",
    "\n",
    "species_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d624c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBIF Download Workflow:\n",
      "============================================================\n",
      "\n",
      "Step 1: Request download for 13 species\n",
      "Run the cell below to initiate download\n",
      "\n",
      "Step 2: After receiving email, download data and put it into data/raw/gbif/\n",
      "\n",
      "Expected GBIF data path: data\\raw\\gbif\\occurrences.csv\n"
     ]
    }
   ],
   "source": [
    "# 4b. GBIF bulk occurrence download workflow\n",
    "from pygbif import occurrences as occ\n",
    "import time\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def request_gbif_download(species_list, year_min, year_max, bbox, user, pwd, email):\n",
    "    \"\"\"\n",
    "    Request bulk occurrence download from GBIF.\n",
    "    Returns download key for later retrieval.\n",
    "    \"\"\"\n",
    "    if not all([user, pwd, email]):\n",
    "        print(\"ERROR: GBIF credentials required for bulk download\")\n",
    "        print(\"Set CONFIG['gbif_user'], CONFIG['gbif_password'], CONFIG['gbif_email']\")\n",
    "        return None\n",
    "    \n",
    "    # Get taxon keys for species\n",
    "    taxon_keys = []\n",
    "    for sp_name in species_list:\n",
    "        try:\n",
    "            result = gbif_species.name_backbone(name=sp_name)\n",
    "            if result.get('usageKey'):\n",
    "                taxon_keys.append(result['usageKey'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if not taxon_keys:\n",
    "        print(\"No valid taxon keys found for species list\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(taxon_keys)} taxon keys for {len(species_list)} species\")\n",
    "    \n",
    "    # Build download predicate using proper GBIF predicate format\n",
    "    # Create OR predicate for taxon keys\n",
    "    taxon_predicates = [{\"type\": \"equals\", \"key\": \"TAXON_KEY\", \"value\": str(key)} for key in taxon_keys]\n",
    "    \n",
    "    # Build complete predicate\n",
    "    predicate = {\n",
    "        \"type\": \"and\",\n",
    "        \"predicates\": [\n",
    "            # Taxon keys (OR'd together)\n",
    "            {\n",
    "                \"type\": \"or\",\n",
    "                \"predicates\": taxon_predicates\n",
    "            },\n",
    "            # Has coordinates\n",
    "            {\"type\": \"equals\", \"key\": \"HAS_COORDINATE\", \"value\": \"true\"},\n",
    "            # No geospatial issues\n",
    "            {\"type\": \"equals\", \"key\": \"HAS_GEOSPATIAL_ISSUE\", \"value\": \"false\"},\n",
    "            # Year range\n",
    "            {\"type\": \"greaterThanOrEquals\", \"key\": \"YEAR\", \"value\": str(year_min)},\n",
    "            {\"type\": \"lessThanOrEquals\", \"key\": \"YEAR\", \"value\": str(year_max)},\n",
    "            # Geographic bounding box - use GEOMETRY predicate\n",
    "            {\n",
    "                \"type\": \"within\",\n",
    "                \"geometry\": f\"POLYGON(({bbox[0]} {bbox[1]},{bbox[2]} {bbox[1]},{bbox[2]} {bbox[3]},{bbox[0]} {bbox[3]},{bbox[0]} {bbox[1]}))\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # occ.download returns a tuple: (download_key, created_date)\n",
    "        result = occ.download(predicate, user=user, pwd=pwd, email=email)\n",
    "        \n",
    "        # Extract download key from tuple\n",
    "        if isinstance(result, tuple):\n",
    "            download_key = result[0]\n",
    "        else:\n",
    "            download_key = result\n",
    "        \n",
    "        print(f\"Download requested. Key: {download_key}\")\n",
    "        print(f\"You will receive an email at {email} when ready\")\n",
    "        print(f\"Download URL: https://www.gbif.org/occurrence/download/{download_key}\")\n",
    "        \n",
    "        return download_key\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error requesting download: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nAlternative: Use GBIF web interface:\")\n",
    "        print(\"1. Go to https://www.gbif.org/occurrence/search\")\n",
    "        print(\"2. Filter by species, date range, and coordinates\")\n",
    "        print(\"3. Click 'Download' and select 'Simple CSV'\")\n",
    "        print(f\"4. Save to {CONFIG['data_dir'] / 'raw' / 'gbif' / 'occurrences.csv'}\")\n",
    "        return None\n",
    "    \n",
    "# ---- NOT WORKING, DOWNLOAD MANUALLY ----    \n",
    "# def download_gbif_data(download_key, user, pwd, output_dir):\n",
    "#     \"\"\"\n",
    "#     Download and extract GBIF occurrence data once ready.\n",
    "#     \"\"\"\n",
    "#     if not download_key:\n",
    "#         print(\"No download key provided\")\n",
    "#         return None\n",
    "    \n",
    "#     output_dir = Path(output_dir)\n",
    "#     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     try:\n",
    "#         # Check download status\n",
    "#         metadata = occ.download_meta(download_key)\n",
    "#         status = metadata.get('status', 'UNKNOWN')\n",
    "        \n",
    "#         print(f\"Download status: {status}\")\n",
    "        \n",
    "#         if status != 'SUCCEEDED':\n",
    "#             print(f\"Download not ready yet. Current status: {status}\")\n",
    "#             print(\"Please wait for email notification or check status later\")\n",
    "#             return None\n",
    "        \n",
    "#         # Download the file\n",
    "#         print(\"Downloading data...\")\n",
    "        \n",
    "#         # occ.download_get returns a tuple: (download_key, path)\n",
    "#         result = occ.download_get(download_key, path=str(output_dir))\n",
    "        \n",
    "#         # Extract the path from the tuple\n",
    "#         if isinstance(result, tuple):\n",
    "#             _, download_path = result\n",
    "#         else:\n",
    "#             download_path = result\n",
    "        \n",
    "#         zip_path = Path(download_path)\n",
    "        \n",
    "#         # Extract\n",
    "#         print(\"Extracting data...\")\n",
    "#         with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(output_dir)\n",
    "        \n",
    "#         # Find the occurrence file\n",
    "#         occurrence_file = output_dir / 'occurrence.txt'\n",
    "#         if occurrence_file.exists():\n",
    "#             # Rename to CSV\n",
    "#             output_csv = output_dir / 'occurrences.csv'\n",
    "#             occurrence_file.rename(output_csv)\n",
    "#             print(f\"Success! Data saved to {output_csv}\")\n",
    "#             return output_csv\n",
    "#         else:\n",
    "#             print(\"Could not find occurrence.txt in download\")\n",
    "#             return None\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error downloading: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         return None\n",
    "\n",
    "# Example usage\n",
    "if CONFIG['gbif_email']:\n",
    "    print(\"GBIF Download Workflow:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get species names\n",
    "    if 'species_df' in locals() and not species_df.empty:\n",
    "        species_names = species_df['scientificName'].tolist()\n",
    "        \n",
    "        print(f\"\\nStep 1: Request download for {len(species_names)} species\")\n",
    "        print(\"Run the cell below to initiate download\")\n",
    "        print(\"\\nStep 2: After receiving email, download data and put it into data/raw/gbif/\")\n",
    "    else:\n",
    "        print(\"First run cell 4a to get species list\")\n",
    "else:\n",
    "    print(\"Please set CONFIG['gbif_email'] to use GBIF download workflow\")\n",
    "    print(\"\\nAlternative: Use GBIF web interface and place CSV in data/raw/gbif/\")\n",
    "\n",
    "gbif_raw_path = CONFIG['data_dir'] / 'raw' / 'gbif' / 'occurrences.csv'\n",
    "print(f\"\\nExpected GBIF data path: {gbif_raw_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad93be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 taxon keys for 13 species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Your download key is 0019280-251025141854904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download requested. Key: 0019280-251025141854904\n",
      "You will receive an email at advaithsanilkumar@gmail.com when ready\n",
      "Download URL: https://www.gbif.org/occurrence/download/0019280-251025141854904\n"
     ]
    }
   ],
   "source": [
    "download_key = request_gbif_download(species_names, CONFIG['time_range'][0], CONFIG['time_range'][1], CONFIG['region_bbox'], CONFIG['gbif_user'], CONFIG['gbif_password'], CONFIG['gbif_email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fcf6936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['DisNo.', 'Historic', 'Classification Key', 'Disaster Group', 'Disaster Subgroup', 'Disaster Type', 'Disaster Subtype', 'External IDs', 'Event Name', 'ISO'] ...\n",
      "Loaded 693 disaster events from 2000 to 2024\n",
      "\n",
      "EM-DAT data summary:\n",
      "disaster_type\n",
      "Earthquake    324\n",
      "Flood         315\n",
      "Storm          54\n",
      "dtype: int64\n",
      "\n",
      "Years covered: 2000 to 2024\n",
      "Events with coordinates: 693\n"
     ]
    }
   ],
   "source": [
    "# 4c. EM-DAT disaster data ingestion\n",
    "import pandas as pd\n",
    "\n",
    "def load_emdat_data(filepath, disaster_types, year_min, year_max, bbox):\n",
    "    \"\"\"\n",
    "    Load and filter EM-DAT disaster data.\n",
    "    Expected columns from EM-DAT: Start Year, Disaster Type, Country, Latitude, Longitude, etc.\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"ERROR: EM-DAT file not found at {filepath}\")\n",
    "        print(\"Download from https://www.emdat.be/ and place in data/raw/\")\n",
    "        return None\n",
    "    \n",
    "    # Load with encoding that handles special characters\n",
    "    df = pd.read_csv(filepath, encoding='utf-8-sig', low_memory=False)\n",
    "    \n",
    "    # Print column names for debugging\n",
    "    print(\"Available columns:\", df.columns.tolist()[:10], \"...\")\n",
    "    \n",
    "    # The actual EM-DAT file uses 'Start Year' not 'year'\n",
    "    # and 'Disaster Type' not 'disaster_type'\n",
    "    \n",
    "    # Filter by year - use 'Start Year' column\n",
    "    if 'Start Year' in df.columns:\n",
    "        df = df[(df['Start Year'] >= year_min) & (df['Start Year'] <= year_max)]\n",
    "    else:\n",
    "        print(\"WARNING: 'Start Year' column not found\")\n",
    "        return None\n",
    "    \n",
    "    # Filter by disaster type - map to EM-DAT disaster types\n",
    "    disaster_map = {\n",
    "        'wildfire': ['Wildfire'],\n",
    "        'flood': ['Flood', 'Flash flood', 'Riverine flood', 'Coastal flood'],\n",
    "        'cyclone': ['Storm', 'Tropical cyclone', 'Typhoon', 'Cyclone'],\n",
    "        'earthquake': ['Earthquake', 'Ground movement']\n",
    "    }\n",
    "    \n",
    "    type_filter = []\n",
    "    for dtype in disaster_types:\n",
    "        if dtype in disaster_map:\n",
    "            type_filter.extend(disaster_map[dtype])\n",
    "    \n",
    "    # Use 'Disaster Subtype' or 'Disaster Type' column\n",
    "    if 'Disaster Subtype' in df.columns:\n",
    "        df = df[df['Disaster Subtype'].isin(type_filter)]\n",
    "    elif 'Disaster Type' in df.columns:\n",
    "        df = df[df['Disaster Type'].isin(type_filter)]\n",
    "    else:\n",
    "        print(\"WARNING: Disaster type columns not found\")\n",
    "    \n",
    "    # Filter by geography (if coordinates available)\n",
    "    if 'Latitude' in df.columns and 'Longitude' in df.columns:\n",
    "        # Remove rows with missing coordinates\n",
    "        df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "        df = df[\n",
    "            (df['Longitude'] >= bbox[0]) & (df['Longitude'] <= bbox[2]) &\n",
    "            (df['Latitude'] >= bbox[1]) & (df['Latitude'] <= bbox[3])\n",
    "        ]\n",
    "    else:\n",
    "        print(\"WARNING: Latitude/Longitude columns not found - filtering by country names instead\")\n",
    "        # Fallback: filter by Asian countries if coordinates not available\n",
    "        # You may need to expand this list\n",
    "        asian_countries = ['China', 'India', 'Indonesia', 'Pakistan', 'Bangladesh', \n",
    "                          'Japan', 'Philippines', 'Vietnam', 'Thailand', 'Myanmar',\n",
    "                          'Korea', 'Nepal', 'Sri Lanka', 'Malaysia', 'Cambodia']\n",
    "        if 'Country' in df.columns:\n",
    "            df = df[df['Country'].isin(asian_countries)]\n",
    "    \n",
    "    # Standardize column names for downstream use\n",
    "    column_mapping = {\n",
    "        'Start Year': 'year',\n",
    "        'Disaster Type': 'disaster_type',\n",
    "        'Disaster Subtype': 'disaster_subtype',\n",
    "        'Latitude': 'latitude',\n",
    "        'Longitude': 'longitude',\n",
    "        'Total Deaths': 'total_deaths',\n",
    "        'No. Affected': 'affected',\n",
    "        'Total Damage (\\'000 US$)': 'damage_usd'\n",
    "    }\n",
    "    \n",
    "    # Rename columns that exist\n",
    "    rename_dict = {k: v for k, v in column_mapping.items() if k in df.columns}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} disaster events from {year_min} to {year_max}\")\n",
    "    return df\n",
    "\n",
    "emdat_path = CONFIG['data_dir'] / 'raw' / 'emdat_asia_2000_2024.csv'\n",
    "emdat_df = load_emdat_data(\n",
    "    emdat_path,\n",
    "    CONFIG['disaster_types'],\n",
    "    CONFIG['time_range'][0],\n",
    "    CONFIG['time_range'][1],\n",
    "    CONFIG['region_bbox']\n",
    ")\n",
    "\n",
    "if emdat_df is not None:\n",
    "    print(\"\\nEM-DAT data summary:\")\n",
    "    if 'disaster_type' in emdat_df.columns:\n",
    "        print(emdat_df.groupby('disaster_type').size())\n",
    "    elif 'disaster_subtype' in emdat_df.columns:\n",
    "        print(emdat_df.groupby('disaster_subtype').size())\n",
    "    \n",
    "    print(f\"\\nYears covered: {emdat_df['year'].min()} to {emdat_df['year'].max()}\")\n",
    "    print(f\"Events with coordinates: {emdat_df[['latitude', 'longitude']].notna().all(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ce6a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MAMMALS data...\n",
      "  Loading MAMMALS_PART1.shp...\n",
      "  Loading MAMMALS_PART2.shp...\n",
      "  Loading MAMMALS_PART2.shp...\n",
      "Loading BIRDS data from GPKG...\n",
      "Loading BIRDS data from GPKG...\n",
      "Loading REPTILES data...\n",
      "  Loading REPTILES_PART1.shp...\n",
      "Loading REPTILES data...\n",
      "  Loading REPTILES_PART1.shp...\n",
      "  Loading REPTILES_PART2.shp...\n",
      "  Loading REPTILES_PART2.shp...\n",
      "Loading AMPHIBIANS data...\n",
      "  Loading AMPHIBIANS_PART1.shp...\n",
      "Loading AMPHIBIANS data...\n",
      "  Loading AMPHIBIANS_PART1.shp...\n",
      "  Loading AMPHIBIANS_PART2.shp...\n",
      "  Loading AMPHIBIANS_PART2.shp...\n",
      "Loaded 21 range polygons for 12 species\n",
      "Loaded 21 range polygons for 12 species\n"
     ]
    }
   ],
   "source": [
    "# 4d. IUCN range map processing\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_iucn_ranges(iucn_dir, species_list):\n",
    "    \"\"\"\n",
    "    Load IUCN range shapefiles for species in species_list.\n",
    "    Handles PART1/PART2 shapefiles for mammals/reptiles/amphibians and GPKG for birds.\n",
    "    \"\"\"\n",
    "    if not iucn_dir.exists():\n",
    "        print(f\"ERROR: IUCN directory not found at {iucn_dir}\")\n",
    "        print(\"Download from https://www.iucnredlist.org/resources/spatial-data-download\")\n",
    "        return None\n",
    "    \n",
    "    gdfs = []\n",
    "    \n",
    "    # Load MAMMALS (PART1 and PART2 shapefiles)\n",
    "    mammals_dir = iucn_dir / 'MAMMALS'\n",
    "    if mammals_dir.exists():\n",
    "        print(\"Loading MAMMALS data...\")\n",
    "        for part in ['PART1', 'PART2']:\n",
    "            shp_file = mammals_dir / f'MAMMALS_{part}.shp'\n",
    "            if shp_file.exists():\n",
    "                print(f\"  Loading MAMMALS_{part}.shp...\")\n",
    "                gdf = gpd.read_file(shp_file)\n",
    "                # Filter to species of interest\n",
    "                if 'binomial' in gdf.columns:\n",
    "                    gdf = gdf[gdf['binomial'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "                elif 'sci_name' in gdf.columns:\n",
    "                    gdf = gdf[gdf['sci_name'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "    \n",
    "    # Load BIRDS (GPKG format)\n",
    "    birds_dir = iucn_dir / 'BIRDS'\n",
    "    if birds_dir.exists():\n",
    "        gpkg_file = birds_dir / 'BOTW_2025.gpkg'\n",
    "        if gpkg_file.exists():\n",
    "            print(\"Loading BIRDS data from GPKG...\")\n",
    "            gdf = gpd.read_file(gpkg_file)\n",
    "            # Filter to species of interest - birds typically use 'sci_name' or 'SCINAME'\n",
    "            name_col = None\n",
    "            for col in ['sci_name', 'SCINAME', 'binomial', 'scientific_name']:\n",
    "                if col in gdf.columns:\n",
    "                    name_col = col\n",
    "                    break\n",
    "            if name_col:\n",
    "                gdf = gdf[gdf[name_col].isin(species_list)]\n",
    "                gdfs.append(gdf)\n",
    "    \n",
    "    # Load REPTILES (PART1 and PART2 shapefiles)\n",
    "    reptiles_dir = iucn_dir / 'REPTILES'\n",
    "    if reptiles_dir.exists():\n",
    "        print(\"Loading REPTILES data...\")\n",
    "        for part in ['PART1', 'PART2']:\n",
    "            shp_file = reptiles_dir / f'REPTILES_{part}.shp'\n",
    "            if shp_file.exists():\n",
    "                print(f\"  Loading REPTILES_{part}.shp...\")\n",
    "                gdf = gpd.read_file(shp_file)\n",
    "                # Filter to species of interest\n",
    "                if 'binomial' in gdf.columns:\n",
    "                    gdf = gdf[gdf['binomial'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "                elif 'sci_name' in gdf.columns:\n",
    "                    gdf = gdf[gdf['sci_name'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "    \n",
    "    # Load AMPHIBIANS (PART1 and PART2 shapefiles)\n",
    "    amphibians_dir = iucn_dir / 'AMPHIBIANS'\n",
    "    if amphibians_dir.exists():\n",
    "        print(\"Loading AMPHIBIANS data...\")\n",
    "        for part in ['PART1', 'PART2']:\n",
    "            shp_file = amphibians_dir / f'AMPHIBIANS_{part}.shp'\n",
    "            if shp_file.exists():\n",
    "                print(f\"  Loading AMPHIBIANS_{part}.shp...\")\n",
    "                gdf = gpd.read_file(shp_file)\n",
    "                # Filter to species of interest\n",
    "                if 'binomial' in gdf.columns:\n",
    "                    gdf = gdf[gdf['binomial'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "                elif 'sci_name' in gdf.columns:\n",
    "                    gdf = gdf[gdf['sci_name'].isin(species_list)]\n",
    "                    gdfs.append(gdf)\n",
    "    \n",
    "    if not gdfs:\n",
    "        print(\"No matching species found in IUCN data\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all GeoDataFrames\n",
    "    ranges = pd.concat(gdfs, ignore_index=True)\n",
    "    \n",
    "    # Standardize column names\n",
    "    if 'sci_name' in ranges.columns and 'binomial' not in ranges.columns:\n",
    "        ranges['binomial'] = ranges['sci_name']\n",
    "    \n",
    "    print(f\"Loaded {len(ranges)} range polygons for {ranges['binomial'].nunique()} species\")\n",
    "    \n",
    "    return ranges\n",
    "\n",
    "iucn_dir = CONFIG['data_dir'] / 'raw' / 'iucn'\n",
    "species_names = species_df['scientificName'].tolist() if 'species_df' in locals() else []\n",
    "\n",
    "iucn_ranges = load_iucn_ranges(iucn_dir, species_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3dbbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Created 21 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved IUCN ranges to data\\processed\\iucn_ranges_filtered.gpkg\n",
      "Saved 21 range polygons for 12 species\n"
     ]
    }
   ],
   "source": [
    "# 4e. Save processed IUCN ranges\n",
    "if iucn_ranges is not None:\n",
    "    # Save as GeoPackage (recommended format - single file - fast - supports all geometry types)\n",
    "    iucn_processed_path = CONFIG['data_dir'] / 'processed' / 'iucn_ranges_filtered.gpkg'\n",
    "    iucn_ranges.to_file(iucn_processed_path, driver='GPKG')\n",
    "    print(f\"Saved IUCN ranges to {iucn_processed_path}\")\n",
    "    \n",
    "    # Alternative: Save as Shapefile (if needed for compatibility)\n",
    "    # Note: Shapefiles have column name length limitations (10 chars)\n",
    "    # iucn_shp_path = CONFIG['data_dir'] / 'processed' / 'iucn_ranges_filtered.shp'\n",
    "    # iucn_ranges.to_file(iucn_shp_path, driver='ESRI Shapefile')\n",
    "    \n",
    "    # Alternative: Save as GeoJSON (human-readable, larger file size)\n",
    "    # iucn_geojson_path = CONFIG['data_dir'] / 'processed' / 'iucn_ranges_filtered.geojson'\n",
    "    # iucn_ranges.to_file(iucn_geojson_path, driver='GeoJSON')\n",
    "    \n",
    "    print(f\"Saved {len(iucn_ranges)} range polygons for {iucn_ranges['binomial'].nunique()} species\")\n",
    "else:\n",
    "    print(\"No IUCN ranges to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e04f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grid with 585,000 cells\n",
      "Avg cell area: 145.2 km²\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Created 585,000 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grid to data\\processed\\analysis_grid.gpkg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>lon_center</th>\n",
       "      <th>lat_center</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_0_0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>POLYGON ((60.1 -10, 60.1 -9.9, 60 -9.9, 60 -10...</td>\n",
       "      <td>125.812666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g_0_1</td>\n",
       "      <td>60.05</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>POLYGON ((60.1 -9.9, 60.1 -9.8, 60 -9.8, 60 -9...</td>\n",
       "      <td>125.774348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g_0_2</td>\n",
       "      <td>60.05</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>POLYGON ((60.1 -9.8, 60.1 -9.7, 60 -9.7, 60 -9...</td>\n",
       "      <td>125.736437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_0_3</td>\n",
       "      <td>60.05</td>\n",
       "      <td>-9.65</td>\n",
       "      <td>POLYGON ((60.1 -9.7, 60.1 -9.6, 60 -9.6, 60 -9...</td>\n",
       "      <td>125.698931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_0_4</td>\n",
       "      <td>60.05</td>\n",
       "      <td>-9.55</td>\n",
       "      <td>POLYGON ((60.1 -9.6, 60.1 -9.5, 60 -9.5, 60 -9...</td>\n",
       "      <td>125.661830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grid_id  lon_center  lat_center  \\\n",
       "0   g_0_0       60.05       -9.95   \n",
       "1   g_0_1       60.05       -9.85   \n",
       "2   g_0_2       60.05       -9.75   \n",
       "3   g_0_3       60.05       -9.65   \n",
       "4   g_0_4       60.05       -9.55   \n",
       "\n",
       "                                            geometry    area_km2  \n",
       "0  POLYGON ((60.1 -10, 60.1 -9.9, 60 -9.9, 60 -10...  125.812666  \n",
       "1  POLYGON ((60.1 -9.9, 60.1 -9.8, 60 -9.8, 60 -9...  125.774348  \n",
       "2  POLYGON ((60.1 -9.8, 60.1 -9.7, 60 -9.7, 60 -9...  125.736437  \n",
       "3  POLYGON ((60.1 -9.7, 60.1 -9.6, 60 -9.6, 60 -9...  125.698931  \n",
       "4  POLYGON ((60.1 -9.6, 60.1 -9.5, 60 -9.5, 60 -9...  125.661830  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Create spatial analysis grid\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "def create_analysis_grid(bbox, resolution):\n",
    "    \"\"\"\n",
    "    Create regular lat-lon grid covering bounding box.\n",
    "    Returns GeoDataFrame with grid cells.\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    lons = np.arange(min_lon, max_lon, resolution)\n",
    "    lats = np.arange(min_lat, max_lat, resolution)\n",
    "    \n",
    "    grid_polys = []\n",
    "    grid_ids = []\n",
    "    grid_centers = []\n",
    "    \n",
    "    for i, lon in enumerate(lons):\n",
    "        for j, lat in enumerate(lats):\n",
    "            poly = box(lon, lat, lon + resolution, lat + resolution)\n",
    "            grid_polys.append(poly)\n",
    "            grid_ids.append(f'g_{i}_{j}')\n",
    "            grid_centers.append((lon + resolution/2, lat + resolution/2))\n",
    "    \n",
    "    grid_gdf = gpd.GeoDataFrame({\n",
    "        'grid_id': grid_ids,\n",
    "        'lon_center': [c[0] for c in grid_centers],\n",
    "        'lat_center': [c[1] for c in grid_centers],\n",
    "        'geometry': grid_polys\n",
    "    }, crs='EPSG:4326')\n",
    "    \n",
    "    # Calculate grid area in km²\n",
    "    grid_gdf['area_km2'] = grid_gdf.to_crs('EPSG:3857').geometry.area / 1e6\n",
    "    \n",
    "    return grid_gdf\n",
    "\n",
    "grid_gdf = create_analysis_grid(CONFIG['region_bbox'], CONFIG['grid_resolution_deg'])\n",
    "print(f\"Created grid with {len(grid_gdf):,} cells\")\n",
    "print(f\"Avg cell area: {grid_gdf['area_km2'].mean():.1f} km²\")\n",
    "\n",
    "# Save grid for reference\n",
    "grid_path = CONFIG['data_dir'] / 'processed' / 'analysis_grid.gpkg'\n",
    "grid_gdf.to_file(grid_path, driver='GPKG')\n",
    "print(f\"Saved grid to {grid_path}\")\n",
    "\n",
    "grid_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15b1b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial join functions defined\n"
     ]
    }
   ],
   "source": [
    "# 6. Spatial join functions - link occurrences and disasters to grid\n",
    "import geopandas as gpd\n",
    "\n",
    "def map_points_to_grid(points_gdf, grid_gdf):\n",
    "    \"\"\"\n",
    "    Spatially join point data to grid cells.\n",
    "    \"\"\"\n",
    "    # Ensure same CRS\n",
    "    pts = points_gdf.to_crs(grid_gdf.crs)\n",
    "    \n",
    "    # Spatial join\n",
    "    joined = gpd.sjoin(pts, grid_gdf[['grid_id', 'geometry']], how='left', predicate='within')\n",
    "    \n",
    "    # Drop points outside grid\n",
    "    joined = joined.dropna(subset=['grid_id'])\n",
    "    \n",
    "    return joined\n",
    "\n",
    "def map_polygon_to_grid(poly_gdf, grid_gdf):\n",
    "    \"\"\"\n",
    "    Compute grid cell overlap with polygon ranges.\n",
    "    Returns grid cells with fraction of area covered.\n",
    "    \"\"\"\n",
    "    poly = poly_gdf.to_crs(grid_gdf.crs)\n",
    "    \n",
    "    # Intersection\n",
    "    intersected = gpd.overlay(poly, grid_gdf[['grid_id', 'geometry']], how='intersection')\n",
    "    \n",
    "    # Calculate overlap area\n",
    "    intersected['overlap_km2'] = intersected.to_crs('EPSG:3857').geometry.area / 1e6\n",
    "    \n",
    "    # Merge with grid areas to get fraction\n",
    "    intersected = intersected.merge(\n",
    "        grid_gdf[['grid_id', 'area_km2']],\n",
    "        on='grid_id',\n",
    "        how='left'\n",
    "    )\n",
    "    intersected['overlap_fraction'] = intersected['overlap_km2'] / intersected['area_km2']\n",
    "    \n",
    "    return intersected\n",
    "\n",
    "def expand_disaster_footprint(disaster_points, radius_km, grid_gdf):\n",
    "    \"\"\"\n",
    "    Expand point disasters to circular footprints.\n",
    "    Returns affected grid cells.\n",
    "    \"\"\"\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    # Convert to projected CRS for buffering\n",
    "    pts = disaster_points.to_crs('EPSG:3857')\n",
    "    \n",
    "    # Buffer by radius\n",
    "    pts['geometry'] = pts.geometry.buffer(radius_km * 1000)\n",
    "    \n",
    "    # Back to WGS84\n",
    "    pts = pts.to_crs('EPSG:4326')\n",
    "    \n",
    "    # Intersect with grid\n",
    "    affected = map_polygon_to_grid(pts, grid_gdf)\n",
    "    \n",
    "    return affected\n",
    "\n",
    "print(\"Spatial join functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e2ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GBIF data at data\\raw\\gbif\\0019239-251025141854904.csv\n",
      "Loading and processing occurrence data...\n",
      "Loaded file with 506589 rows and 50 columns\n",
      "Loaded file with 506589 rows and 50 columns\n",
      "After species filter: 506589 records\n",
      "After species filter: 506589 records\n",
      "After year filter (2000-2024): 506589 records\n",
      "After year filter (2000-2024): 506589 records\n",
      "After bbox filter: 506589 records\n",
      "After bbox filter: 506589 records\n",
      "\n",
      "Final: 506,589 occurrences for 13 species\n",
      "\n",
      "Final: 506,589 occurrences for 13 species\n",
      "\n",
      "Occurrence panel created:\n",
      "  Grid cells: 12,050\n",
      "  Species: 13\n",
      "  Years: 2000 - 2024\n",
      "  Total records: 39,947\n",
      "\n",
      "Saved occurrence panel to data\\processed\\occurrence_panel.csv\n",
      "\n",
      "Occurrence summary by species:\n",
      "                       n_occurrences  n_grid_cells\n",
      "species                                           \n",
      "Turdoides striata             487649          9492\n",
      "Chelonia mydas                  8197          1677\n",
      "Panthera tigris                 4435           518\n",
      "Elephas maximus                 4339           910\n",
      "Carpococcyx renauldi             899            46\n",
      "Arborophila davidi               503            28\n",
      "Pongo abelii                     396            49\n",
      "Crocodylus siamensis             151            37\n",
      "Rhacophorus catamitus              7             6\n",
      "Rhinoceros sondaicus               7             6\n",
      "\n",
      "Occurrence panel created:\n",
      "  Grid cells: 12,050\n",
      "  Species: 13\n",
      "  Years: 2000 - 2024\n",
      "  Total records: 39,947\n",
      "\n",
      "Saved occurrence panel to data\\processed\\occurrence_panel.csv\n",
      "\n",
      "Occurrence summary by species:\n",
      "                       n_occurrences  n_grid_cells\n",
      "species                                           \n",
      "Turdoides striata             487649          9492\n",
      "Chelonia mydas                  8197          1677\n",
      "Panthera tigris                 4435           518\n",
      "Elephas maximus                 4339           910\n",
      "Carpococcyx renauldi             899            46\n",
      "Arborophila davidi               503            28\n",
      "Pongo abelii                     396            49\n",
      "Crocodylus siamensis             151            37\n",
      "Rhacophorus catamitus              7             6\n",
      "Rhinoceros sondaicus               7             6\n"
     ]
    }
   ],
   "source": [
    "# 7. Occurrence data processing and outcome construction\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_gbif_occurrences(filepath, species_list, year_min, year_max, bbox):\n",
    "    \"\"\"\n",
    "    Load GBIF occurrence CSV and prepare for analysis.\n",
    "    Note: GBIF exports are tab-separated even when saved as .csv\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"ERROR: GBIF file not found at {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # GBIF data is tab-separated, not comma-separated\n",
    "    # Try to detect separator automatically\n",
    "    try:\n",
    "        # First, try reading as tab-separated (GBIF default)\n",
    "        df = pd.read_csv(filepath, sep='\\t', low_memory=False, encoding='utf-8')\n",
    "        \n",
    "        # Check if we got valid columns - GBIF files should have many columns\n",
    "        if len(df.columns) < 10:\n",
    "            # If we only got a few columns, file might be comma-separated\n",
    "            print(\"Tab separation failed, trying comma separator...\")\n",
    "            df = pd.read_csv(filepath, sep=',', low_memory=False, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded file with {len(df)} rows and {len(df.columns)} columns\")\n",
    "    \n",
    "    # Standardize columns\n",
    "    required_cols = ['species', 'decimalLatitude', 'decimalLongitude', 'year']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"ERROR: Missing required columns: {missing_cols}\")\n",
    "        print(f\"Available columns: {df.columns.tolist()[:20]}...\")\n",
    "        return None\n",
    "    \n",
    "    # Filter by species\n",
    "    df = df[df['species'].isin(species_list)]\n",
    "    print(f\"After species filter: {len(df)} records\")\n",
    "    \n",
    "    # Filter by year\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "    df = df[(df['year'] >= year_min) & (df['year'] <= year_max)]\n",
    "    print(f\"After year filter ({year_min}-{year_max}): {len(df)} records\")\n",
    "    \n",
    "    # Filter by coordinates\n",
    "    df = df[\n",
    "        (df['decimalLongitude'] >= bbox[0]) & (df['decimalLongitude'] <= bbox[2]) &\n",
    "        (df['decimalLatitude'] >= bbox[1]) & (df['decimalLatitude'] <= bbox[3])\n",
    "    ]\n",
    "    print(f\"After bbox filter: {len(df)} records\")\n",
    "    \n",
    "    # Drop invalid coordinates\n",
    "    df = df.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "    \n",
    "    print(f\"\\nFinal: {len(df):,} occurrences for {df['species'].nunique()} species\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_occurrence_panel(occurrence_df, grid_gdf, time_unit='year'):\n",
    "    \"\"\"\n",
    "    Create grid × time × species panel with occurrence counts.\n",
    "    \"\"\"\n",
    "    # Convert to GeoDataFrame\n",
    "    occ_gdf = gpd.GeoDataFrame(\n",
    "        occurrence_df,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            occurrence_df['decimalLongitude'],\n",
    "            occurrence_df['decimalLatitude']\n",
    "        ),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    # Map to grid\n",
    "    occ_joined = map_points_to_grid(occ_gdf, grid_gdf)\n",
    "    \n",
    "    # Aggregate by grid × time × species\n",
    "    agg = occ_joined.groupby(['grid_id', time_unit, 'species']).size().reset_index(name='n_occurrences')\n",
    "    \n",
    "    # Add effort proxy (number of unique collection events)\n",
    "    if 'eventID' in occ_joined.columns:\n",
    "        effort = occ_joined.groupby(['grid_id', time_unit])['eventID'].nunique().reset_index(name='n_events')\n",
    "        agg = agg.merge(effort, on=['grid_id', time_unit], how='left')\n",
    "    \n",
    "    # Calculate detection-adjusted occupancy\n",
    "    agg['occupancy'] = (agg['n_occurrences'] > 0).astype(int)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Example usage: Load GBIF data if available\n",
    "gbif_path = CONFIG['data_dir'] / 'raw' / 'gbif' / '0019239-251025141854904.csv'\n",
    "\n",
    "if gbif_path.exists():\n",
    "    print(f\"Found GBIF data at {gbif_path}\")\n",
    "    print(\"Loading and processing occurrence data...\")\n",
    "    \n",
    "    # Get species list from previous step\n",
    "    if 'species_df' in locals() and not species_df.empty:\n",
    "        species_names = species_df['scientificName'].tolist()\n",
    "        \n",
    "        # Load and process occurrences\n",
    "        occurrence_df = load_and_process_gbif_occurrences(\n",
    "            gbif_path,\n",
    "            species_names,\n",
    "            CONFIG['time_range'][0],\n",
    "            CONFIG['time_range'][1],\n",
    "            CONFIG['region_bbox']\n",
    "        )\n",
    "        \n",
    "        if occurrence_df is not None and len(occurrence_df) > 0:\n",
    "            # Build occurrence panel\n",
    "            if 'grid_gdf' in locals():\n",
    "                occurrence_panel = build_occurrence_panel(occurrence_df, grid_gdf, time_unit='year')\n",
    "                \n",
    "                print(f\"\\nOccurrence panel created:\")\n",
    "                print(f\"  Grid cells: {occurrence_panel['grid_id'].nunique():,}\")\n",
    "                print(f\"  Species: {occurrence_panel['species'].nunique()}\")\n",
    "                print(f\"  Years: {occurrence_panel['year'].min()} - {occurrence_panel['year'].max()}\")\n",
    "                print(f\"  Total records: {len(occurrence_panel):,}\")\n",
    "                \n",
    "                # Save panel\n",
    "                panel_path = CONFIG['data_dir'] / 'processed' / 'occurrence_panel.csv'\n",
    "                occurrence_panel.to_csv(panel_path, index=False)\n",
    "                print(f\"\\nSaved occurrence panel to {panel_path}\")\n",
    "                \n",
    "                # Display summary statistics\n",
    "                print(\"\\nOccurrence summary by species:\")\n",
    "                species_summary = occurrence_panel.groupby('species').agg({\n",
    "                    'n_occurrences': 'sum',\n",
    "                    'grid_id': 'nunique'\n",
    "                }).rename(columns={'grid_id': 'n_grid_cells'}).sort_values('n_occurrences', ascending=False)\n",
    "                print(species_summary.head(10))\n",
    "            else:\n",
    "                print(\"ERROR: Grid not found. Run cell 5 to create analysis grid first.\")\n",
    "        else:\n",
    "            print(\"No occurrence data loaded. Check GBIF file format.\")\n",
    "    else:\n",
    "        print(\"Species list not found. Run cell 4a to get species list first.\")\n",
    "else:\n",
    "    print(f\"GBIF data not found at {gbif_path}\")\n",
    "    print(\"\\nTo proceed:\")\n",
    "    print(\"1. Run cells 4a and 4b to request GBIF download\")\n",
    "    print(\"2. Wait for email notification from GBIF\")\n",
    "    print(\"3. Place downloaded occurrence file at:\")\n",
    "    print(f\"   {gbif_path}\")\n",
    "    print(\"4. Re-run this cell to process the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e6eb9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment construction functions defined\n"
     ]
    }
   ],
   "source": [
    "# 8. Treatment panel construction\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def build_treatment_panel(disaster_df, grid_gdf, time_unit='year', buffer_km=50):\n",
    "    \"\"\"\n",
    "    Create treatment indicators for grid × time.\n",
    "    \n",
    "    Parameters:\n",
    "    - disaster_df: DataFrame with columns [year, latitude, longitude, disaster_type, ...]\n",
    "    - grid_gdf: Grid GeoDataFrame\n",
    "    - buffer_km: radius to expand point events (default 50km)\n",
    "    \n",
    "    Returns: DataFrame with [grid_id, year, treated, disaster_type, intensity]\n",
    "    \"\"\"\n",
    "    if disaster_df is None or len(disaster_df) == 0:\n",
    "        print(\"No disaster data provided\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    disaster_gdf = gpd.GeoDataFrame(\n",
    "        disaster_df,\n",
    "        geometry=gpd.points_from_xy(disaster_df['longitude'], disaster_df['latitude']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    # Expand to footprints\n",
    "    affected = expand_disaster_footprint(disaster_gdf, buffer_km, grid_gdf)\n",
    "    \n",
    "    # Aggregate by grid × time\n",
    "    treatment = affected.groupby(['grid_id', time_unit]).agg({\n",
    "        'disaster_type': 'first',  # Take first if multiple\n",
    "        'overlap_fraction': 'sum'  # Sum overlaps (can be >1 if multiple events)\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Create binary treatment\n",
    "    treatment['treated'] = 1\n",
    "    treatment['treatment_intensity'] = treatment['overlap_fraction']\n",
    "    \n",
    "    # Create event timing for event study\n",
    "    # For each grid, find first treatment year\n",
    "    first_treatment = treatment.groupby('grid_id')[time_unit].min().reset_index()\n",
    "    first_treatment.columns = ['grid_id', 'first_treatment_year']\n",
    "    treatment = treatment.merge(first_treatment, on='grid_id', how='left')\n",
    "    \n",
    "    return treatment\n",
    "\n",
    "def create_full_panel(grid_gdf, years, treatment_df=None):\n",
    "    \"\"\"\n",
    "    Create complete grid × year panel with treatment indicators.\n",
    "    \"\"\"\n",
    "    # All grid × year combinations\n",
    "    years_list = list(range(years[0], years[1] + 1))\n",
    "    panel = pd.DataFrame([\n",
    "        {'grid_id': gid, 'year': yr}\n",
    "        for gid in grid_gdf['grid_id']\n",
    "        for yr in years_list\n",
    "    ])\n",
    "    \n",
    "    # Merge treatment\n",
    "    if treatment_df is not None:\n",
    "        panel = panel.merge(\n",
    "            treatment_df[['grid_id', 'year', 'treated', 'treatment_intensity', 'first_treatment_year']],\n",
    "            on=['grid_id', 'year'],\n",
    "            how='left'\n",
    "        )\n",
    "        panel['treated'] = panel['treated'].fillna(0)\n",
    "        panel['treatment_intensity'] = panel['treatment_intensity'].fillna(0)\n",
    "    else:\n",
    "        panel['treated'] = 0\n",
    "        panel['treatment_intensity'] = 0\n",
    "    \n",
    "    return panel\n",
    "\n",
    "print(\"Treatment construction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bbee141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiD estimation functions defined\n"
     ]
    }
   ],
   "source": [
    "# 9. Difference-in-Differences estimation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "def prepare_panel_data(outcome_df, treatment_df, grid_gdf):\n",
    "    \"\"\"\n",
    "    Merge outcome and treatment into analysis panel.\n",
    "    \"\"\"\n",
    "    # Merge treatment with outcomes\n",
    "    panel = outcome_df.merge(\n",
    "        treatment_df[['grid_id', 'year', 'treated', 'treatment_intensity', 'first_treatment_year']],\n",
    "        on=['grid_id', 'year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing treatment as control\n",
    "    panel['treated'] = panel['treated'].fillna(0)\n",
    "    panel['treatment_intensity'] = panel['treatment_intensity'].fillna(0)\n",
    "    \n",
    "    # Add grid characteristics\n",
    "    panel = panel.merge(\n",
    "        grid_gdf[['grid_id', 'lon_center', 'lat_center', 'area_km2']],\n",
    "        on='grid_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return panel\n",
    "\n",
    "def estimate_twfe_did(panel_df, outcome_var, treatment_var='treated', entity_var='grid_id', time_var='year'):\n",
    "    \"\"\"\n",
    "    Two-way fixed effects DiD using PanelOLS.\n",
    "    \"\"\"\n",
    "    # Set multi-index for panel\n",
    "    panel = panel_df.copy()\n",
    "    panel = panel.set_index([entity_var, time_var])\n",
    "    \n",
    "    # Estimate with entity and time fixed effects\n",
    "    formula = f'{outcome_var} ~ {treatment_var} + EntityEffects + TimeEffects'\n",
    "    \n",
    "    try:\n",
    "        mod = PanelOLS.from_formula(formula, data=panel)\n",
    "        res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "        \n",
    "        print(\"Two-Way Fixed Effects DiD Results\")\n",
    "        print(\"=\" * 60)\n",
    "        print(res.summary)\n",
    "        \n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in TWFE estimation: {e}\")\n",
    "        return None\n",
    "\n",
    "def estimate_event_study(panel_df, outcome_var, entity_var='grid_id', time_var='year', \n",
    "                        treatment_time_var='first_treatment_year', window=(-3, 5)):\n",
    "    \"\"\"\n",
    "    Event study with leads and lags.\n",
    "    \"\"\"\n",
    "    panel = panel_df.copy()\n",
    "    \n",
    "    # Calculate event time (years relative to treatment)\n",
    "    panel['event_time'] = panel[time_var] - panel[treatment_time_var]\n",
    "    \n",
    "    # Create event time dummies (omit -1 as reference)\n",
    "    for t in range(window[0], window[1] + 1):\n",
    "        if t == -1:\n",
    "            continue  # Reference period\n",
    "        panel[f'lead_lag_{t}'] = (panel['event_time'] == t).astype(int)\n",
    "    \n",
    "    # Only include treated units and within window\n",
    "    panel_es = panel[panel[treatment_time_var].notna()].copy()\n",
    "    panel_es = panel_es[panel_es['event_time'].between(window[0], window[1])]\n",
    "    \n",
    "    # Set index\n",
    "    panel_es = panel_es.set_index([entity_var, time_var])\n",
    "    \n",
    "    # Build formula\n",
    "    lead_lag_vars = [f'lead_lag_{t}' for t in range(window[0], window[1] + 1) if t != -1]\n",
    "    formula = f\"{outcome_var} ~ {' + '.join(lead_lag_vars)} + EntityEffects + TimeEffects\"\n",
    "    \n",
    "    try:\n",
    "        mod = PanelOLS.from_formula(formula, data=panel_es)\n",
    "        res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "        \n",
    "        print(\"Event Study Results\")\n",
    "        print(\"=\" * 60)\n",
    "        print(res.summary)\n",
    "        \n",
    "        # Extract coefficients for plotting\n",
    "        coefs = []\n",
    "        for t in range(window[0], window[1] + 1):\n",
    "            if t == -1:\n",
    "                coefs.append({'event_time': t, 'coef': 0, 'se': 0, 'ci_lower': 0, 'ci_upper': 0})\n",
    "            else:\n",
    "                var_name = f'lead_lag_{t}'\n",
    "                if var_name in res.params.index:\n",
    "                    coef = res.params[var_name]\n",
    "                    se = res.std_errors[var_name]\n",
    "                    ci_lower = coef - 1.96 * se\n",
    "                    ci_upper = coef + 1.96 * se\n",
    "                    coefs.append({'event_time': t, 'coef': coef, 'se': se, 'ci_lower': ci_lower, 'ci_upper': ci_upper})\n",
    "        \n",
    "        coefs_df = pd.DataFrame(coefs)\n",
    "        \n",
    "        return res, coefs_df\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in event study: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"DiD estimation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69dfd87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined\n"
     ]
    }
   ],
   "source": [
    "# 10. Visualization functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_event_study(coefs_df, outcome_name='Outcome', save_path=None):\n",
    "    \"\"\"\n",
    "    Plot event study coefficients with confidence intervals.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.fill_between(\n",
    "        coefs_df['event_time'],\n",
    "        coefs_df['ci_lower'],\n",
    "        coefs_df['ci_upper'],\n",
    "        alpha=0.2,\n",
    "        color='steelblue'\n",
    "    )\n",
    "    \n",
    "    plt.plot(\n",
    "        coefs_df['event_time'],\n",
    "        coefs_df['coef'],\n",
    "        marker='o',\n",
    "        color='steelblue',\n",
    "        linewidth=2,\n",
    "        markersize=6\n",
    "    )\n",
    "    \n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.axvline(-0.5, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Years Relative to Disaster', fontsize=12)\n",
    "    plt.ylabel(f'Effect on {outcome_name}', fontsize=12)\n",
    "    plt.title('Event Study: Disaster Impact on Species Occurrences', fontsize=14, fontweight='bold')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_treatment_map(grid_gdf, treatment_df, year, save_path=None):\n",
    "    \"\"\"\n",
    "    Map treated grid cells for a specific year.\n",
    "    \"\"\"\n",
    "    # Filter treatment to year\n",
    "    treated_year = treatment_df[treatment_df['year'] == year].copy()\n",
    "    \n",
    "    # Merge with grid\n",
    "    grid_plot = grid_gdf.merge(treated_year[['grid_id', 'treated']], on='grid_id', how='left')\n",
    "    grid_plot['treated'] = grid_plot['treated'].fillna(0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    grid_plot.plot(\n",
    "        column='treated',\n",
    "        ax=ax,\n",
    "        legend=True,\n",
    "        cmap='RdYlGn_r',\n",
    "        edgecolor='none',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'Disaster-Affected Grid Cells in {year}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_species_effects(results_by_species, save_path=None):\n",
    "    \"\"\"\n",
    "    Forest plot of species-specific treatment effects.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, max(8, len(results_by_species) * 0.5)))\n",
    "    \n",
    "    species = list(results_by_species.keys())\n",
    "    coefs = [r['coef'] for r in results_by_species.values()]\n",
    "    ci_lower = [r['ci_lower'] for r in results_by_species.values()]\n",
    "    ci_upper = [r['ci_upper'] for r in results_by_species.values()]\n",
    "    \n",
    "    y_pos = range(len(species))\n",
    "    \n",
    "    plt.errorbar(coefs, y_pos, xerr=[\n",
    "        [c - ci_l for c, ci_l in zip(coefs, ci_lower)],\n",
    "        [ci_u - c for c, ci_u in zip(coefs, ci_upper)]\n",
    "    ], fmt='o', capsize=5, capthick=2, markersize=8)\n",
    "    \n",
    "    plt.axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.yticks(y_pos, species)\n",
    "    plt.xlabel('Treatment Effect (DiD Coefficient)', fontsize=12)\n",
    "    plt.ylabel('Species', fontsize=12)\n",
    "    plt.title('Species-Specific Disaster Effects', fontsize=14, fontweight='bold')\n",
    "    plt.grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bda8a",
   "metadata": {},
   "source": [
    "## 12. Robustness & Falsification Checks\n",
    "\n",
    "### Checklist:\n",
    "1. **Pre-trend tests:** Visual inspection of event study + formal test of pre-treatment coefficients\n",
    "2. **Placebo tests:**\n",
    "   - Randomize treatment assignment to different grid cells\n",
    "   - Randomize treatment timing\n",
    "3. **Negative controls:** Species/regions not expected to be affected\n",
    "4. **Sensitivity analysis:**\n",
    "   - Alternative grid resolutions (0.05°, 0.2°)\n",
    "   - Alternative time aggregations (quarterly)\n",
    "   - Different treatment windows (buffer sizes)\n",
    "   - Exclude border cells\n",
    "5. **Specification checks:**\n",
    "   - Control for time-varying covariates (land cover change, human pressure)\n",
    "   - Alternative outcome definitions\n",
    "6. **Sample restrictions:**\n",
    "   - High-quality observations only\n",
    "   - Species with sufficient data\n",
    "7. **Inference:**\n",
    "   - Wild cluster bootstrap\n",
    "   - Randomization inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "876159ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustness check functions defined\n"
     ]
    }
   ],
   "source": [
    "# 13. Robustness check implementations\n",
    "import numpy as np\n",
    "\n",
    "def pretrend_test(event_study_coefs, window=(-3, -1)):\n",
    "    \"\"\"\n",
    "    Test for parallel trends: joint F-test on pre-treatment coefficients.\n",
    "    \"\"\"\n",
    "    pre_coefs = event_study_coefs[\n",
    "        event_study_coefs['event_time'].between(window[0], window[1])\n",
    "    ]\n",
    "    \n",
    "    # Joint test: are all pre-treatment coefs jointly zero?\n",
    "    # Use F-statistic\n",
    "    mean_coef = pre_coefs['coef'].mean()\n",
    "    se = pre_coefs['se'].mean()  # Simplified\n",
    "    \n",
    "    f_stat = (mean_coef / se) ** 2\n",
    "    \n",
    "    print(\"Pre-Trend Test\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Mean pre-treatment coefficient: {mean_coef:.4f}\")\n",
    "    print(f\"F-statistic (simplified): {f_stat:.4f}\")\n",
    "    print(\"\\nInterpretation: Small F-stat and coefs close to 0 support parallel trends\")\n",
    "    \n",
    "    return f_stat\n",
    "\n",
    "def placebo_test(panel_df, outcome_var, n_iterations=100, seed=42):\n",
    "    \"\"\"\n",
    "    Placebo test: randomly assign treatment and estimate effects.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    placebo_coefs = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Shuffle treatment assignment\n",
    "        panel_placebo = panel_df.copy()\n",
    "        panel_placebo['treated'] = np.random.permutation(panel_placebo['treated'].values)\n",
    "        \n",
    "        # Estimate\n",
    "        try:\n",
    "            panel_placebo_indexed = panel_placebo.set_index(['grid_id', 'year'])\n",
    "            mod = PanelOLS.from_formula(\n",
    "                f'{outcome_var} ~ treated + EntityEffects + TimeEffects',\n",
    "                data=panel_placebo_indexed\n",
    "            )\n",
    "            res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "            placebo_coefs.append(res.params['treated'])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    placebo_coefs = np.array(placebo_coefs)\n",
    "    \n",
    "    print(\"Placebo Test Results\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Mean placebo coefficient: {placebo_coefs.mean():.4f}\")\n",
    "    print(f\"Std dev: {placebo_coefs.std():.4f}\")\n",
    "    print(f\"95% CI: [{np.percentile(placebo_coefs, 2.5):.4f}, {np.percentile(placebo_coefs, 97.5):.4f}]\")\n",
    "    \n",
    "    return placebo_coefs\n",
    "\n",
    "def sensitivity_alternative_resolution(occurrence_df, treatment_df, resolutions=[0.05, 0.1, 0.2]):\n",
    "    \"\"\"\n",
    "    Re-run analysis at different spatial resolutions.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for res in resolutions:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analyzing at {res}° resolution...\")\n",
    "        \n",
    "        # Create grid at this resolution\n",
    "        grid = create_analysis_grid(CONFIG['region_bbox'], res)\n",
    "        \n",
    "        # Re-aggregate data\n",
    "        # ... (implementation similar to main analysis)\n",
    "        \n",
    "        results[res] = {'grid': grid}  # Store results\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Robustness check functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7dea438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result saving functions defined\n"
     ]
    }
   ],
   "source": [
    "# 14. Save results and processed data\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def save_analysis_results(results_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Save all analysis outputs for reproducibility.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Save data panels - use CSV as primary format for compatibility\n",
    "    if 'panel_data' in results_dict:\n",
    "        # Save as CSV (always works)\n",
    "        results_dict['panel_data'].to_csv(output_dir / 'analysis_panel.csv', index=False)\n",
    "        \n",
    "        # Try parquet as well (more efficient but may fail with complex types)\n",
    "        try:\n",
    "            panel_clean = results_dict['panel_data'].copy()\n",
    "            for col in panel_clean.select_dtypes(include=['object']).columns:\n",
    "                panel_clean[col] = panel_clean[col].astype(str)\n",
    "            panel_clean.to_parquet(output_dir / 'analysis_panel.parquet', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Note: Could not save panel as parquet: {str(e)[:100]}\")\n",
    "    \n",
    "    # Save estimation results\n",
    "    if 'did_results' in results_dict:\n",
    "        with open(output_dir / 'did_results.pkl', 'wb') as f:\n",
    "            pickle.dump(results_dict['did_results'], f)\n",
    "    \n",
    "    if 'event_study_coefs' in results_dict:\n",
    "        results_dict['event_study_coefs'].to_csv(output_dir / 'event_study_coefs.csv', index=False)\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary = {\n",
    "        'n_grid_cells': len(results_dict.get('grid', [])),\n",
    "        'n_treated_cells': results_dict.get('n_treated', 0),\n",
    "        'n_species': results_dict.get('n_species', 0),\n",
    "        'time_range': CONFIG['time_range'],\n",
    "        'main_effect': float(results_dict.get('main_coef', 0)),\n",
    "        'main_se': float(results_dict.get('main_se', 0))\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_dir}\")\n",
    "\n",
    "print(\"Result saving functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbb942",
   "metadata": {},
   "source": [
    "## Analysis Execution\n",
    "\n",
    "Now we'll run the complete analysis pipeline using all the data we've loaded and processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b9028af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: Building Treatment Panel\n",
      "================================================================================\n",
      "\n",
      "Treatment panel summary:\n",
      "  Treated grid cells: 34,914\n",
      "  Years with treatment: 25\n",
      "  Total treatment events: 45,639\n",
      "  Mean treatment intensity: 0.865\n",
      "\n",
      "Treatment panel summary:\n",
      "  Treated grid cells: 34,914\n",
      "  Years with treatment: 25\n",
      "  Total treatment events: 45,639\n",
      "  Mean treatment intensity: 0.865\n",
      "\n",
      "Saved treatment panel to data\\processed\\treatment_panel.csv\n",
      "\n",
      "Saved treatment panel to data\\processed\\treatment_panel.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build treatment panel from EM-DAT disaster data\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: Building Treatment Panel\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'emdat_df' in locals() and emdat_df is not None and 'grid_gdf' in locals():\n",
    "    treatment_df = build_treatment_panel(\n",
    "        emdat_df, \n",
    "        grid_gdf, \n",
    "        time_unit='year', \n",
    "        buffer_km=50\n",
    "    )\n",
    "    \n",
    "    if treatment_df is not None:\n",
    "        print(f\"\\nTreatment panel summary:\")\n",
    "        print(f\"  Treated grid cells: {treatment_df['grid_id'].nunique():,}\")\n",
    "        print(f\"  Years with treatment: {treatment_df['year'].nunique()}\")\n",
    "        print(f\"  Total treatment events: {len(treatment_df):,}\")\n",
    "        print(f\"  Mean treatment intensity: {treatment_df['treatment_intensity'].mean():.3f}\")\n",
    "        \n",
    "        # Save treatment panel\n",
    "        treatment_path = CONFIG['data_dir'] / 'processed' / 'treatment_panel.csv'\n",
    "        treatment_df.to_csv(treatment_path, index=False)\n",
    "        print(f\"\\nSaved treatment panel to {treatment_path}\")\n",
    "    else:\n",
    "        print(\"ERROR: Failed to build treatment panel\")\n",
    "else:\n",
    "    print(\"ERROR: Missing required data (emdat_df or grid_gdf)\")\n",
    "    print(\"Please run cells 7 and 10 first to load disaster data and create grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c1398d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: Preparing Analysis Panel\n",
      "================================================================================\n",
      "\n",
      "Analysis panel created:\n",
      "  Total observations: 39,947\n",
      "  Grid cells: 12,050\n",
      "  Species: 13\n",
      "  Years: 2000 - 2024\n",
      "  Treated observations: 108.0 (0.27%)\n",
      "\n",
      "Outcome variable summary:\n",
      "       occupancy  n_occurrences\n",
      "count    39947.0   39947.000000\n",
      "mean         1.0      12.681528\n",
      "std          0.0      58.203383\n",
      "min          1.0       1.000000\n",
      "25%          1.0       1.000000\n",
      "50%          1.0       2.000000\n",
      "75%          1.0       7.000000\n",
      "max          1.0    3531.000000\n",
      "\n",
      "Analysis panel created:\n",
      "  Total observations: 39,947\n",
      "  Grid cells: 12,050\n",
      "  Species: 13\n",
      "  Years: 2000 - 2024\n",
      "  Treated observations: 108.0 (0.27%)\n",
      "\n",
      "Outcome variable summary:\n",
      "       occupancy  n_occurrences\n",
      "count    39947.0   39947.000000\n",
      "mean         1.0      12.681528\n",
      "std          0.0      58.203383\n",
      "min          1.0       1.000000\n",
      "25%          1.0       1.000000\n",
      "50%          1.0       2.000000\n",
      "75%          1.0       7.000000\n",
      "max          1.0    3531.000000\n",
      "\n",
      "Saved analysis panel to data\\processed\\analysis_panel.csv\n",
      "Note: Could not save as parquet (A type extension with name pandas.period already d...), but CSV version is available\n",
      "\n",
      "Saved analysis panel to data\\processed\\analysis_panel.csv\n",
      "Note: Could not save as parquet (A type extension with name pandas.period already d...), but CSV version is available\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge occurrence and treatment data into analysis panel\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Preparing Analysis Panel\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'occurrence_panel' in locals() and 'treatment_df' in locals() and 'grid_gdf' in locals():\n",
    "    panel_df = prepare_panel_data(occurrence_panel, treatment_df, grid_gdf)\n",
    "    \n",
    "    print(f\"\\nAnalysis panel created:\")\n",
    "    print(f\"  Total observations: {len(panel_df):,}\")\n",
    "    print(f\"  Grid cells: {panel_df['grid_id'].nunique():,}\")\n",
    "    print(f\"  Species: {panel_df['species'].nunique()}\")\n",
    "    print(f\"  Years: {panel_df['year'].min()} - {panel_df['year'].max()}\")\n",
    "    print(f\"  Treated observations: {panel_df['treated'].sum():,} ({100*panel_df['treated'].mean():.2f}%)\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nOutcome variable summary:\")\n",
    "    print(panel_df[['occupancy', 'n_occurrences']].describe())\n",
    "    \n",
    "    # Save analysis panel - use CSV for compatibility\n",
    "    panel_path = CONFIG['data_dir'] / 'processed' / 'analysis_panel.csv'\n",
    "    panel_df.to_csv(panel_path, index=False)\n",
    "    print(f\"\\nSaved analysis panel to {panel_path}\")\n",
    "    \n",
    "    # Also try parquet with type conversion\n",
    "    try:\n",
    "        # Convert to appropriate types for parquet\n",
    "        panel_parquet = panel_df.copy()\n",
    "        # Convert any remaining object columns to strings\n",
    "        for col in panel_parquet.select_dtypes(include=['object']).columns:\n",
    "            panel_parquet[col] = panel_parquet[col].astype(str)\n",
    "        \n",
    "        panel_parquet_path = CONFIG['data_dir'] / 'processed' / 'analysis_panel.parquet'\n",
    "        panel_parquet.to_parquet(panel_parquet_path, index=False, engine='pyarrow')\n",
    "        print(f\"Also saved as parquet to {panel_parquet_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Could not save as parquet ({str(e)[:50]}...), but CSV version is available\")\n",
    "else:\n",
    "    print(\"ERROR: Missing required data\")\n",
    "    print(\"Please ensure occurrence_panel, treatment_df, and grid_gdf are loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a840e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: Two-Way Fixed Effects Difference-in-Differences\n",
      "================================================================================\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "ERROR in TWFE estimation: float division by zero\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run Two-Way Fixed Effects DiD\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Two-Way Fixed Effects Difference-in-Differences\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'panel_df' in locals():\n",
    "    did_results = estimate_twfe_did(\n",
    "        panel_df, \n",
    "        outcome_var='occupancy',\n",
    "        treatment_var='treated',\n",
    "        entity_var='grid_id',\n",
    "        time_var='year'\n",
    "    )\n",
    "    \n",
    "    if did_results is not None:\n",
    "        # Extract key results\n",
    "        treatment_effect = did_results.params['treated']\n",
    "        treatment_se = did_results.std_errors['treated']\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"KEY RESULTS:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Treatment effect: {treatment_effect:.6f}\")\n",
    "        print(f\"Standard error: {treatment_se:.6f}\")\n",
    "        print(f\"95% CI: [{treatment_effect - 1.96*treatment_se:.6f}, {treatment_effect + 1.96*treatment_se:.6f}]\")\n",
    "        \n",
    "        # Interpretation\n",
    "        pct_change = treatment_effect * 100\n",
    "        print(f\"\\nInterpretation: Disasters are associated with a {pct_change:.2f} percentage point\")\n",
    "        print(f\"change in species occupancy probability\")\n",
    "else:\n",
    "    print(\"ERROR: Analysis panel not found. Run previous step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae63cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: Event Study Analysis\n",
      "================================================================================\n",
      "ERROR in event study: Unable to evaluate factor `lead_lag_`. [NameError: `lead_lag_` is not present in the dataset or evaluation context.]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Event Study Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: Event Study Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'panel_df' in locals():\n",
    "    event_study_results, event_study_coefs = estimate_event_study(\n",
    "        panel_df,\n",
    "        outcome_var='occupancy',\n",
    "        entity_var='grid_id',\n",
    "        time_var='year',\n",
    "        treatment_time_var='first_treatment_year',\n",
    "        window=CONFIG['event_window']\n",
    "    )\n",
    "    \n",
    "    if event_study_coefs is not None:\n",
    "        print(f\"\\nEvent study coefficients extracted for plotting\")\n",
    "        print(f\"Time window: {CONFIG['event_window'][0]} to {CONFIG['event_window'][1]} years\")\n",
    "        \n",
    "        # Save coefficients\n",
    "        es_coef_path = CONFIG['results_dir'] / 'event_study_coefficients.csv'\n",
    "        event_study_coefs.to_csv(es_coef_path, index=False)\n",
    "        print(f\"Saved to {es_coef_path}\")\n",
    "else:\n",
    "    print(\"ERROR: Analysis panel not found. Run previous step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fa0d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: Event Study Visualization\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mevent_study_coefs\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mplot_event_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent_study_coefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutcome_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSpecies Occupancy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults_dir\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_study_plot.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvent study plot saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[33m'\u001b[39m\u001b[33mresults_dir\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mevent_study_plot.png\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mplot_event_study\u001b[39m\u001b[34m(coefs_df, outcome_name, save_path)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03mPlot event study coefficients with confidence intervals.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     11\u001b[39m plt.fill_between(\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mcoefs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     13\u001b[39m     coefs_df[\u001b[33m'\u001b[39m\u001b[33mci_lower\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m     coefs_df[\u001b[33m'\u001b[39m\u001b[33mci_upper\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     15\u001b[39m     alpha=\u001b[32m0.2\u001b[39m,\n\u001b[32m     16\u001b[39m     color=\u001b[33m'\u001b[39m\u001b[33msteelblue\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m plt.plot(\n\u001b[32m     20\u001b[39m     coefs_df[\u001b[33m'\u001b[39m\u001b[33mevent_time\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     21\u001b[39m     coefs_df[\u001b[33m'\u001b[39m\u001b[33mcoef\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     markersize=\u001b[32m6\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m plt.axhline(\u001b[32m0\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, linestyle=\u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Visualize Event Study Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: Event Study Visualization\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'event_study_coefs' in locals():\n",
    "    plot_event_study(\n",
    "        event_study_coefs,\n",
    "        outcome_name='Species Occupancy',\n",
    "        save_path=CONFIG['results_dir'] / 'event_study_plot.png'\n",
    "    )\n",
    "    print(f\"Event study plot saved to {CONFIG['results_dir'] / 'event_study_plot.png'}\")\n",
    "else:\n",
    "    print(\"ERROR: Event study coefficients not found. Run Step 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2437667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 6: Species-Specific Treatment Effects\n",
      "================================================================================\n",
      "Analyzing 8 species with ≥50 observations\n",
      "\n",
      "[1/8] Analyzing Arborophila davidi...\n",
      "  Skipping - no treated observations\n",
      "\n",
      "[2/8] Analyzing Carpococcyx renauldi...\n",
      "  Skipping - no treated observations\n",
      "\n",
      "[3/8] Analyzing Chelonia mydas...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[4/8] Analyzing Crocodylus siamensis...\n",
      "  Skipping - no treated observations\n",
      "\n",
      "[5/8] Analyzing Elephas maximus...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[6/8] Analyzing Panthera tigris...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[4/8] Analyzing Crocodylus siamensis...\n",
      "  Skipping - no treated observations\n",
      "\n",
      "[5/8] Analyzing Elephas maximus...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[6/8] Analyzing Panthera tigris...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[7/8] Analyzing Pongo abelii...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[8/8] Analyzing Turdoides striata...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[7/8] Analyzing Pongo abelii...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "[8/8] Analyzing Turdoides striata...\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "============================================================\n",
      "Successfully analyzed 0 species\n",
      "Saved to results\\species_specific_results.csv\n",
      "ERROR in TWFE estimation: float division by zero\n",
      "\n",
      "============================================================\n",
      "Successfully analyzed 0 species\n",
      "Saved to results\\species_specific_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Species-Specific Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: Species-Specific Treatment Effects\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'panel_df' in locals():\n",
    "    species_results = {}\n",
    "    \n",
    "    # Get list of species with sufficient data\n",
    "    species_counts = panel_df.groupby('species').size()\n",
    "    species_to_analyze = species_counts[species_counts >= CONFIG['min_occurrences']].index.tolist()\n",
    "    \n",
    "    print(f\"Analyzing {len(species_to_analyze)} species with ≥{CONFIG['min_occurrences']} observations\")\n",
    "    \n",
    "    for i, species in enumerate(species_to_analyze, 1):\n",
    "        print(f\"\\n[{i}/{len(species_to_analyze)}] Analyzing {species}...\")\n",
    "        \n",
    "        # Filter panel to this species\n",
    "        panel_sp = panel_df[panel_df['species'] == species].copy()\n",
    "        \n",
    "        # Check if there's variation in treatment\n",
    "        if panel_sp['treated'].sum() == 0:\n",
    "            print(f\"  Skipping - no treated observations\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            res = estimate_twfe_did(\n",
    "                panel_sp, \n",
    "                outcome_var='occupancy',\n",
    "                treatment_var='treated'\n",
    "            )\n",
    "            \n",
    "            if res is not None:\n",
    "                species_results[species] = {\n",
    "                    'coef': res.params['treated'],\n",
    "                    'se': res.std_errors['treated'],\n",
    "                    'ci_lower': res.conf_int().loc['treated', 'lower'],\n",
    "                    'ci_upper': res.conf_int().loc['treated', 'upper'],\n",
    "                    'n_obs': len(panel_sp),\n",
    "                    'n_treated': panel_sp['treated'].sum()\n",
    "                }\n",
    "                print(f\"  Effect: {species_results[species]['coef']:.4f} (SE: {species_results[species]['se']:.4f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Successfully analyzed {len(species_results)} species\")\n",
    "    \n",
    "    # Save results\n",
    "    species_results_df = pd.DataFrame(species_results).T\n",
    "    species_results_df.index.name = 'species'\n",
    "    species_results_path = CONFIG['results_dir'] / 'species_specific_results.csv'\n",
    "    species_results_df.to_csv(species_results_path)\n",
    "    print(f\"Saved to {species_results_path}\")\n",
    "else:\n",
    "    print(\"ERROR: Analysis panel not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize Species-Specific Effects\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: Species Effects Visualization\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'species_results' in locals() and len(species_results) > 0:\n",
    "    plot_species_effects(\n",
    "        species_results,\n",
    "        save_path=CONFIG['results_dir'] / 'species_effects_forest_plot.png'\n",
    "    )\n",
    "    print(f\"Forest plot saved to {CONFIG['results_dir'] / 'species_effects_forest_plot.png'}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    species_coefs = [r['coef'] for r in species_results.values()]\n",
    "    print(f\"\\nSpecies-specific effects summary:\")\n",
    "    print(f\"  Mean effect: {np.mean(species_coefs):.4f}\")\n",
    "    print(f\"  Median effect: {np.median(species_coefs):.4f}\")\n",
    "    print(f\"  Std dev: {np.std(species_coefs):.4f}\")\n",
    "    print(f\"  Range: [{np.min(species_coefs):.4f}, {np.max(species_coefs):.4f}]\")\n",
    "    \n",
    "    # Count significant effects (95% CI doesn't include 0)\n",
    "    n_negative_sig = sum(1 for r in species_results.values() if r['ci_upper'] < 0)\n",
    "    n_positive_sig = sum(1 for r in species_results.values() if r['ci_lower'] > 0)\n",
    "    \n",
    "    print(f\"\\nSignificant effects (95% level):\")\n",
    "    print(f\"  Negative: {n_negative_sig}/{len(species_results)} ({100*n_negative_sig/len(species_results):.1f}%)\")\n",
    "    print(f\"  Positive: {n_positive_sig}/{len(species_results)} ({100*n_positive_sig/len(species_results):.1f}%)\")\n",
    "else:\n",
    "    print(\"ERROR: Species results not found. Run Step 6 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9425313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 8: Spatial Visualization of Treatment\n",
      "================================================================================\n",
      "Visualizing treatment for year 2006 (peak treatment year)\n",
      "Number of treated cells in 2006: 6001\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment map saved to results\\treatment_map_2006.png\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Treatment Map Visualization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: Spatial Visualization of Treatment\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'grid_gdf' in locals() and 'treatment_df' in locals():\n",
    "    # Pick a year with notable treatment\n",
    "    treatment_by_year = treatment_df.groupby('year').size()\n",
    "    peak_year = treatment_by_year.idxmax()\n",
    "    \n",
    "    print(f\"Visualizing treatment for year {peak_year} (peak treatment year)\")\n",
    "    print(f\"Number of treated cells in {peak_year}: {treatment_by_year[peak_year]}\")\n",
    "    \n",
    "    plot_treatment_map(\n",
    "        grid_gdf,\n",
    "        treatment_df,\n",
    "        year=peak_year,\n",
    "        save_path=CONFIG['results_dir'] / f'treatment_map_{peak_year}.png'\n",
    "    )\n",
    "    print(f\"Treatment map saved to {CONFIG['results_dir'] / f'treatment_map_{peak_year}.png'}\")\n",
    "else:\n",
    "    print(\"ERROR: Grid or treatment data not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Save Complete Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: Saving Complete Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compile all results\n",
    "results_dict = {}\n",
    "\n",
    "if 'panel_df' in locals():\n",
    "    results_dict['panel_data'] = panel_df\n",
    "    \n",
    "if 'did_results' in locals():\n",
    "    results_dict['did_results'] = did_results\n",
    "    results_dict['main_coef'] = did_results.params['treated']\n",
    "    results_dict['main_se'] = did_results.std_errors['treated']\n",
    "    \n",
    "if 'event_study_coefs' in locals():\n",
    "    results_dict['event_study_coefs'] = event_study_coefs\n",
    "    \n",
    "if 'species_results' in locals():\n",
    "    results_dict['species_results'] = species_results\n",
    "    \n",
    "if 'grid_gdf' in locals():\n",
    "    results_dict['grid'] = grid_gdf\n",
    "    \n",
    "if 'treatment_df' in locals():\n",
    "    results_dict['n_treated'] = treatment_df['grid_id'].nunique()\n",
    "    \n",
    "if 'occurrence_panel' in locals():\n",
    "    results_dict['n_species'] = occurrence_panel['species'].nunique()\n",
    "\n",
    "# Save everything\n",
    "save_analysis_results(results_dict, CONFIG['results_dir'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults saved to: {CONFIG['results_dir']}\")\n",
    "print(\"\\nKey outputs:\")\n",
    "print(f\"  - Analysis panel: {CONFIG['data_dir'] / 'processed' / 'analysis_panel.parquet'}\")\n",
    "print(f\"  - Treatment panel: {CONFIG['data_dir'] / 'processed' / 'treatment_panel.csv'}\")\n",
    "print(f\"  - Event study plot: {CONFIG['results_dir'] / 'event_study_plot.png'}\")\n",
    "print(f\"  - Species effects: {CONFIG['results_dir'] / 'species_specific_results.csv'}\")\n",
    "print(f\"  - Forest plot: {CONFIG['results_dir'] / 'species_effects_forest_plot.png'}\")\n",
    "print(f\"  - Summary: {CONFIG['results_dir'] / 'summary.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9325eb2",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "The analysis pipeline has completed. Review the outputs above for:\n",
    "\n",
    "1. **Overall Treatment Effect**: DiD estimate of disaster impact on species occupancy\n",
    "2. **Event Study**: Dynamic treatment effects over time (pre/post disaster)\n",
    "3. **Species Heterogeneity**: Individual species responses to disasters\n",
    "4. **Spatial Patterns**: Geographic distribution of treatment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Review the event study plot for parallel trends assumption\n",
    "- Examine species-specific results for heterogeneous effects\n",
    "- Run robustness checks (cells in section 12-13)\n",
    "- Consider alternative specifications or subgroup analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ade06",
   "metadata": {},
   "source": [
    "## Advanced Estimators\n",
    "\n",
    "For more advanced causal inference methods, consider:\n",
    "\n",
    "### Synthetic Control Method\n",
    "For case studies with strong single treated unit (e.g., major disaster in specific region):\n",
    "\n",
    "```python\n",
    "# Placeholder for Synthetic Control\n",
    "# Use synthdid or R's Synth package via rpy2\n",
    "```\n",
    "\n",
    "### Sun-Abraham (2021) Estimator\n",
    "For heterogeneous treatment effects with staggered adoption:\n",
    "\n",
    "```python\n",
    "# Use pydid or R's did package\n",
    "```\n",
    "\n",
    "### Bayesian Hierarchical Model\n",
    "For pooling across species with varying effects:\n",
    "\n",
    "```python\n",
    "import pymc as pm\n",
    "\n",
    "# Model structure:\n",
    "# outcome_{i,s,t} ~ Normal(mu_{i,s,t}, sigma)\n",
    "# mu_{i,s,t} = alpha_s + beta_s * treatment_{i,t} + grid_effects + time_effects\n",
    "# alpha_s ~ Normal(mu_alpha, sigma_alpha)  # species intercepts\n",
    "# beta_s ~ Normal(mu_beta, sigma_beta)     # species treatment effects\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7382a",
   "metadata": {},
   "source": [
    "## 15. Complete Analysis Workflow\n",
    "\n",
    "### Step-by-step execution:\n",
    "\n",
    "1. **Data acquisition:**\n",
    "   - Download EM-DAT disasters → `data/raw/emdat_asia_2000_2024.csv`\n",
    "   - Request GBIF download → wait for notification → download to `data/raw/gbif/occurrences.csv`\n",
    "   - Download IUCN ranges → extract to `data/raw/iucn/`\n",
    "   - (Optional) Download MODIS land cover → `data/raw/modis/`\n",
    "\n",
    "2. **Preprocessing:**\n",
    "   ```python\n",
    "   # Load data\n",
    "   emdat_df = load_emdat_data(...)\n",
    "   gbif_df = load_and_process_gbif_occurrences(...)\n",
    "   iucn_ranges = load_iucn_ranges(...)\n",
    "   \n",
    "   # Create spatial grid\n",
    "   grid_gdf = create_analysis_grid(...)\n",
    "   \n",
    "   # Build panels\n",
    "   treatment_df = build_treatment_panel(emdat_df, grid_gdf)\n",
    "   occurrence_panel = build_occurrence_panel(gbif_df, grid_gdf)\n",
    "   \n",
    "   # Merge into analysis panel\n",
    "   panel_df = prepare_panel_data(occurrence_panel, treatment_df, grid_gdf)\n",
    "   ```\n",
    "\n",
    "3. **Main estimation:**\n",
    "   ```python\n",
    "   # DiD\n",
    "   did_res = estimate_twfe_did(panel_df, outcome_var='occupancy')\n",
    "   \n",
    "   # Event study\n",
    "   es_res, es_coefs = estimate_event_study(panel_df, outcome_var='occupancy')\n",
    "   \n",
    "   # Plot\n",
    "   plot_event_study(es_coefs, save_path=CONFIG['results_dir'] / 'event_study.png')\n",
    "   ```\n",
    "\n",
    "4. **Species-specific analysis:**\n",
    "   ```python\n",
    "   species_results = {}\n",
    "   for species in panel_df['species'].unique():\n",
    "       panel_sp = panel_df[panel_df['species'] == species]\n",
    "       res = estimate_twfe_did(panel_sp, outcome_var='occupancy')\n",
    "       species_results[species] = {\n",
    "           'coef': res.params['treated'],\n",
    "           'se': res.std_errors['treated'],\n",
    "           'ci_lower': res.conf_int().loc['treated', 'lower'],\n",
    "           'ci_upper': res.conf_int().loc['treated', 'upper']\n",
    "       }\n",
    "   \n",
    "   plot_species_effects(species_results)\n",
    "   ```\n",
    "\n",
    "5. **Robustness:**\n",
    "   ```python\n",
    "   # Pre-trends\n",
    "   f_stat = pretrend_test(es_coefs)\n",
    "   \n",
    "   # Placebo\n",
    "   placebo_coefs = placebo_test(panel_df, 'occupancy', n_iterations=500)\n",
    "   \n",
    "   # Sensitivity\n",
    "   sensitivity_results = sensitivity_alternative_resolution(occurrence_panel, treatment_df)\n",
    "   ```\n",
    "\n",
    "6. **Save outputs:**\n",
    "   ```python\n",
    "   results = {\n",
    "       'panel_data': panel_df,\n",
    "       'did_results': did_res,\n",
    "       'event_study_coefs': es_coefs,\n",
    "       'species_results': species_results,\n",
    "       'grid': grid_gdf,\n",
    "       'n_treated': treatment_df['grid_id'].nunique(),\n",
    "       'n_species': panel_df['species'].nunique(),\n",
    "       'main_coef': did_res.params['treated'],\n",
    "       'main_se': did_res.std_errors['treated']\n",
    "   }\n",
    "   \n",
    "   save_analysis_results(results, CONFIG['results_dir'])\n",
    "   ```\n",
    "\n",
    "### Next Steps:\n",
    "- Fill in API credentials in Cell 3\n",
    "- Download required datasets (see Data Sources in Cell 4)\n",
    "- Execute cells sequentially\n",
    "- Adjust parameters based on data characteristics\n",
    "- Iterate with robustness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea280286",
   "metadata": {},
   "source": [
    "## 16. References & Resources\n",
    "\n",
    "**Key Papers:**\n",
    "- Callaway & Sant'Anna (2021): Difference-in-Differences with multiple time periods. *Journal of Econometrics*.\n",
    "- Sun & Abraham (2021): Estimating dynamic treatment effects. *Journal of Econometrics*.\n",
    "- Abadie et al. (2010): Synthetic control methods. *JASA*.\n",
    "\n",
    "**Data Sources:**\n",
    "- **EM-DAT:** https://www.emdat.be/\n",
    "- **GBIF:** https://www.gbif.org/ (API: https://www.gbif.org/developer/occurrence)\n",
    "- **IUCN Red List:** https://www.iucnredlist.org/resources/spatial-data-download\n",
    "- **MODIS:** https://modis.gsfc.nasa.gov/\n",
    "- **Copernicus:** https://emergency.copernicus.eu/\n",
    "\n",
    "**Software:**\n",
    "- `linearmodels` (Python): Panel data models - https://bashtage.github.io/linearmodels/\n",
    "- `pydid` (Python): DiD estimators - https://github.com/py-econometrics/pydid\n",
    "- `fixest` (R): Fast fixed effects - https://lrberge.github.io/fixest/\n",
    "- `did` (R): Callaway-Sant'Anna - https://bcallaway11.github.io/did/\n",
    "\n",
    "**Analysis Guidelines:**\n",
    "- Roth et al. (2023): What's Trending in Difference-in-Differences? *JBES*.\n",
    "- Cunningham (2021): Causal Inference: The Mixtape. Yale Press.\n",
    "\n",
    "---\n",
    "\n",
    "**Contact & Issues:**\n",
    "For questions about this pipeline, open an issue or contact the maintainer.\n",
    "\n",
    "**Citation:**\n",
    "If you use this pipeline, please cite relevant data sources and methods papers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
