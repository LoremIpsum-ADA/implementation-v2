{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a1e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas numpy tqdm requests python-dateutil earthengine-api google-cloud-storage google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a38f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cf602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis panel shape: (39947, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>species</th>\n",
       "      <th>n_occurrences</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>treated</th>\n",
       "      <th>treatment_intensity</th>\n",
       "      <th>lon_center</th>\n",
       "      <th>lat_center</th>\n",
       "      <th>area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_0_321</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>22.15</td>\n",
       "      <td>133.794339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g_0_322</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>22.25</td>\n",
       "      <td>133.889669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g_0_323</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>22.35</td>\n",
       "      <td>133.985543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_0_324</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>22.45</td>\n",
       "      <td>134.081963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_0_325</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chelonia mydas</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.05</td>\n",
       "      <td>22.55</td>\n",
       "      <td>134.178931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id  year         species  n_occurrences  occupancy  treated  \\\n",
       "0  g_0_321  2018  Chelonia mydas              1          1        0   \n",
       "1  g_0_322  2018  Chelonia mydas              1          1        0   \n",
       "2  g_0_323  2018  Chelonia mydas              2          1        0   \n",
       "3  g_0_324  2018  Chelonia mydas              4          1        0   \n",
       "4  g_0_325  2018  Chelonia mydas              2          1        0   \n",
       "\n",
       "   treatment_intensity  lon_center  lat_center    area_km2  \n",
       "0                  0.0       60.05       22.15  133.794339  \n",
       "1                  0.0       60.05       22.25  133.889669  \n",
       "2                  0.0       60.05       22.35  133.985543  \n",
       "3                  0.0       60.05       22.45  134.081963  \n",
       "4                  0.0       60.05       22.55  134.178931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = \"data/processed/\"\n",
    "\n",
    "df= pd.read_csv(os.path.join(base_path, \"analysis_panel.csv\"))\n",
    "print(\"Analysis panel shape:\", df.shape)\n",
    "\n",
    "# df = pd.read_csv(base_path)\n",
    "df.drop(columns=['first_treatment_year'], inplace = True)\n",
    "\n",
    "df['treated'] = df['treated'].astype(int)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5d33d",
   "metadata": {},
   "source": [
    "# Appending Covariates \n",
    "The following code block basically adds these 5 features to the df:\n",
    "\n",
    "- temp_mean_(Â°C) Â°C âˆ’10 â†’ +35 Mean annual air temperature\n",
    "- precip_sum_(mm/year) mm/year 0 â†’ 3000 Total yearly rainfall\n",
    "- humidity_mean_(%) % 20 â†’ 100 Mean relative humidity\n",
    "- ndvi_mean_(0â€“1) 0â€“1 (dimensionless) 0 (bare) â†’ 1 (lush) Vegetation greenness\n",
    "- human_density_(people/kmÂ²) people per kmÂ² 0 â†’ 50,000 Population density\n",
    "\n",
    "each column header follows the max resolution it can use. \n",
    "\n",
    "## Apis Used:\n",
    "OpenMeteo - > temp + precip \n",
    "NASA Power -> humidity \n",
    "Google Earth Engine -> ndvi + Human density\n",
    "\n",
    "## To configure Google Earth Engine \n",
    "\n",
    "1. Make a google earth engine account at https://code.earthengine.google.com/\n",
    "2. Make a new project (non commercial) and sound as broke as you can, convince it u dont want to make money off it \n",
    "3. run this -> ``` earthengine authenticate ``` in cmd -> this opens ur browser -> login to the acc wit GEE configured\n",
    "4. below  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28672575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 3 unique location-year combinations...\n",
      "Already cached: 0, Need to fetch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ NASA humidity error 22.15,60.05,2018: 429 Client Error: Too Many Requests for url: https://power.larc.nasa.gov/api/temporal/daily/point?parameters=RH2M&latitude=22.15&longitude=60.05&start=20180101&end=20181231&community=AG&format=JSON\n",
      "âš ï¸ NDVI fail 22.15,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n",
      "âš ï¸ WorldPop fail 22.15,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:07<00:15,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ NASA humidity error 22.25,60.05,2018: 429 Client Error: Too Many Requests for url: https://power.larc.nasa.gov/api/temporal/daily/point?parameters=RH2M&latitude=22.25&longitude=60.05&start=20180101&end=20181231&community=AG&format=JSON\n",
      "âš ï¸ NDVI fail 22.25,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n",
      "âš ï¸ WorldPop fail 22.25,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:15<00:07,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ NASA humidity error 22.35,60.05,2018: 429 Client Error: Too Many Requests for url: https://power.larc.nasa.gov/api/temporal/daily/point?parameters=RH2M&latitude=22.35&longitude=60.05&start=20180101&end=20181231&community=AG&format=JSON\n",
      "âš ï¸ NDVI fail 22.35,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n",
      "âš ï¸ WorldPop fail 22.35,60.05,2018: Earth Engine client library not initialized. See http://goo.gle/ee-auth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Filling dataframe with cached results...\n",
      "ðŸ’¾ Cache saved to data/processed/climate_cache.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 751.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Results:\n",
      "   grid_id  year  lat_center  lon_center temp_mean_(Â°C)_(25x25km)  \\\n",
      "0  g_0_321  2018       22.15       60.05                25.418904   \n",
      "1  g_0_322  2018       22.25       60.05                25.506164   \n",
      "2  g_0_323  2018       22.35       60.05                25.569863   \n",
      "\n",
      "  precip_sum_(mm/year)_(25x25km) humidity_mean_(%)_(50x50km)  \\\n",
      "0                            4.2                        None   \n",
      "1                            4.3                        None   \n",
      "2                            5.4                        None   \n",
      "\n",
      "  ndvi_mean_(0â€“1)_(0.25x0.25km) human_density_(people/kmÂ²)_(0.1x0.1km)  \n",
      "0                          None                                   None  \n",
      "1                          None                                   None  \n",
      "2                          None                                   None  \n",
      "\n",
      "ðŸ’¾ Saved to climate_data_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸŒ Improved Climate Covariate Fetcher with Proper Batching\n",
    "# ============================================================\n",
    "import requests, time, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ee\n",
    "\n",
    "def init_earth_engine():\n",
    "    \"\"\"Authenticate and initialize Earth Engine safely (works for Colab & VSCode).\"\"\"\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "        print(\"ðŸŒ Earth Engine initialized (existing credentials).\")\n",
    "    except Exception as e:\n",
    "        print(\"ðŸ”‘ Authenticating Earth Engine...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "        print(\"âœ… Earth Engine successfully initialized!\")\n",
    "\n",
    "# ------------------ 1ï¸âƒ£ OPEN-METEO (Individual requests with smart caching) ------------------\n",
    "def fetch_open_meteo_single(lat, lon, year):\n",
    "    \"\"\"Fetch temperature & precipitation for a single location.\"\"\"\n",
    "    try:\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"start_date\": f\"{year}-01-01\",\n",
    "            \"end_date\": f\"{year}-12-31\",\n",
    "            \"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\"],\n",
    "            \"timezone\": \"UTC\",\n",
    "        }\n",
    "        r = requests.get(url, params=params, timeout=60)\n",
    "        \n",
    "        if r.status_code == 429:\n",
    "            print(\"âš ï¸ Rate limit hit â€“ pausing 60s\")\n",
    "            time.sleep(60)\n",
    "            return fetch_open_meteo_single(lat, lon, year)\n",
    "        \n",
    "        r.raise_for_status()\n",
    "        js = r.json()\n",
    "        d = js.get(\"daily\", {})\n",
    "        \n",
    "        result = {}\n",
    "        if d and \"temperature_2m_max\" in d and \"temperature_2m_min\" in d:\n",
    "            temps = [(a + b)/2 for a, b in zip(d[\"temperature_2m_max\"], d[\"temperature_2m_min\"]) \n",
    "                     if a is not None and b is not None]\n",
    "            if temps:\n",
    "                result[\"temp_mean_(Â°C)_(25x25km)\"] = np.mean(temps)\n",
    "        \n",
    "        if d and \"precipitation_sum\" in d:\n",
    "            precip = [p for p in d[\"precipitation_sum\"] if p is not None]\n",
    "            if precip:\n",
    "                result[\"precip_sum_(mm/year)_(25x25km)\"] = np.sum(precip)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Open-Meteo error for {lat},{lon},{year}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# ------------------ 2ï¸âƒ£ NASA POWER (Humidity) ------------------\n",
    "def fetch_nasa_humidity(lat, lon, year):\n",
    "    \"\"\"Fetch mean relative humidity.\"\"\"\n",
    "    try:\n",
    "        url = (\n",
    "            f\"https://power.larc.nasa.gov/api/temporal/daily/point?\"\n",
    "            f\"parameters=RH2M\"\n",
    "            f\"&latitude={lat}&longitude={lon}\"\n",
    "            f\"&start={year}0101&end={year}1231\"\n",
    "            f\"&community=AG&format=JSON\"\n",
    "        )\n",
    "        r = requests.get(url, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        data = r.json().get(\"properties\", {}).get(\"parameter\", {})\n",
    "        \n",
    "        if \"RH2M\" in data:\n",
    "            rh_values = [v for v in data[\"RH2M\"].values() if v is not None and v != -999]\n",
    "            if rh_values:\n",
    "                return {\"humidity_mean_(%)_(50x50km)\": np.mean(rh_values)}\n",
    "        \n",
    "        return {\"humidity_mean_(%)_(50x50km)\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ NASA humidity error {lat},{lon},{year}: {e}\")\n",
    "        return {\"humidity_mean_(%)_(50x50km)\": None}\n",
    "\n",
    "# ------------------ 3ï¸âƒ£ EARTH ENGINE (NDVI + Human coverage) ------------------\n",
    "def fetch_gee_vars(lat, lon, year):\n",
    "    \"\"\"Fetch MODIS NDVI + WorldPop density.\"\"\"\n",
    "    import ee\n",
    "    \n",
    "    res = {\n",
    "        \"ndvi_mean_(0â€“1)_(0.25x0.25km)\": None, \n",
    "        \"human_density_(people/kmÂ²)_(0.1x0.1km)\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        point = ee.Geometry.Point(lon, lat)\n",
    "        \n",
    "        # NDVI\n",
    "        ndvi_coll = (ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n",
    "                     .filterDate(f\"{year}-01-01\", f\"{year}-12-31\")\n",
    "                     .select(\"NDVI\"))\n",
    "        \n",
    "        if ndvi_coll.size().getInfo() > 0:\n",
    "            ndvi_mean = ndvi_coll.mean().reduceRegion(\n",
    "                ee.Reducer.mean(), \n",
    "                point.buffer(5500), \n",
    "                250\n",
    "            ).get(\"NDVI\").getInfo()\n",
    "            \n",
    "            if ndvi_mean is not None:\n",
    "                res[\"ndvi_mean_(0â€“1)_(0.25x0.25km)\"] = ndvi_mean / 10000\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ NDVI fail {lat},{lon},{year}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # WorldPop\n",
    "        pop_coll = (ee.ImageCollection(\"WorldPop/GP/100m/pop\")\n",
    "                    .filterDate(f\"{year}-01-01\", f\"{year}-12-31\"))\n",
    "        \n",
    "        if pop_coll.size().getInfo() > 0:\n",
    "            pop = pop_coll.mean().reduceRegion(\n",
    "                ee.Reducer.mean(), \n",
    "                point.buffer(5500), \n",
    "                100\n",
    "            ).get(\"population\").getInfo()\n",
    "            \n",
    "            if pop is not None:\n",
    "                res[\"human_density_(people/kmÂ²)_(0.1x0.1km)\"] = pop\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ WorldPop fail {lat},{lon},{year}: {e}\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "# ------------------ 4ï¸âƒ£ COMBINED WRAPPER WITH SMART BATCHING ------------------\n",
    "def append_covariates(df, lat_col=\"lat_center\", lon_col=\"lon_center\", year_col=\"year\", \n",
    "                     requests_per_minute=60, use_gee=True, \n",
    "                     cache_file=\"data/processed/climate_cache.json\", \n",
    "                     checkpoint_file=\"data/processed/climate_checkpoint.csv\",\n",
    "                     checkpoint_interval=100):\n",
    "    \"\"\"\n",
    "    Append climate covariates with proper rate limiting, caching, and checkpointing.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        lat_col, lon_col, year_col: Column names\n",
    "        requests_per_minute: Rate limit for API calls\n",
    "        use_gee: Whether to fetch Google Earth Engine data (requires ee module)\n",
    "        cache_file: JSON file to store API results cache\n",
    "        checkpoint_file: CSV file to save progress checkpoints\n",
    "        checkpoint_interval: Save checkpoint every N requests\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize columns\n",
    "    cols = [\n",
    "        \"temp_mean_(Â°C)_(25x25km)\",\n",
    "        \"precip_sum_(mm/year)_(25x25km)\",\n",
    "        \"humidity_mean_(%)_(50x50km)\",\n",
    "        \"ndvi_mean_(0â€“1)_(0.25x0.25km)\",\n",
    "        \"human_density_(people/kmÂ²)_(0.1x0.1km)\",\n",
    "    ]\n",
    "    for c in cols:\n",
    "        df[c] = None\n",
    "    \n",
    "    # Load existing cache if available\n",
    "    cache = {}\n",
    "    if os.path.exists(cache_file):\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                cache_raw = json.load(f)\n",
    "                # Convert string keys back to tuples\n",
    "                cache = {eval(k): v for k, v in cache_raw.items()}\n",
    "            print(f\"âœ“ Loaded {len(cache)} entries from cache: {cache_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not load cache: {e}\")\n",
    "    \n",
    "    # Get unique location-year combinations\n",
    "    unique_rows = df[[lat_col, lon_col, year_col]].drop_duplicates()\n",
    "    total = len(unique_rows)\n",
    "    \n",
    "    # Count how many we already have cached\n",
    "    already_cached = sum(1 for _, row in unique_rows.iterrows() \n",
    "                        if (round(float(row[lat_col]), 3), \n",
    "                            round(float(row[lon_col]), 3), \n",
    "                            int(row[year_col])) in cache)\n",
    "    \n",
    "    print(f\"Fetching data for {total} unique location-year combinations...\")\n",
    "    print(f\"Already cached: {already_cached}, Need to fetch: {total - already_cached}\")\n",
    "    \n",
    "    # Calculate delay between requests to respect rate limit\n",
    "    delay = 60.0 / requests_per_minute\n",
    "    \n",
    "    def save_cache():\n",
    "        \"\"\"Save cache to JSON file.\"\"\"\n",
    "        try:\n",
    "            # Convert tuple keys to strings for JSON\n",
    "            cache_serializable = {str(k): v for k, v in cache.items()}\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache_serializable, f, indent=2)\n",
    "            print(f\"ðŸ’¾ Cache saved to {cache_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error saving cache: {e}\")\n",
    "    \n",
    "    def save_checkpoint():\n",
    "        \"\"\"Save current progress to checkpoint file.\"\"\"\n",
    "        try:\n",
    "            df_current = fill_dataframe_from_cache(df.copy(), cache, cols, \n",
    "                                                   lat_col, lon_col, year_col)\n",
    "            df_current.to_csv( checkpoint_file, index=False)\n",
    "            print(f\"ðŸ’¾ Checkpoint saved to {checkpoint_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error saving checkpoint: {e}\")\n",
    "    \n",
    "    # Process each unique location-year\n",
    "    try:\n",
    "        for idx, (_, row) in enumerate(tqdm(unique_rows.iterrows(), total=total)):\n",
    "            lat = round(float(row[lat_col]), 3)\n",
    "            lon = round(float(row[lon_col]), 3)\n",
    "            year = int(row[year_col])\n",
    "            \n",
    "            key = (lat, lon, year)\n",
    "            \n",
    "            if key in cache:\n",
    "                continue\n",
    "            \n",
    "            # Fetch all data for this location\n",
    "            result = {}\n",
    "            \n",
    "            # Open-Meteo (temp + precip)\n",
    "            result.update(fetch_open_meteo_single(lat, lon, year))\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # NASA (humidity)\n",
    "            result.update(fetch_nasa_humidity(lat, lon, year))\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Google Earth Engine (NDVI + population) - if enabled\n",
    "            if use_gee:\n",
    "                try:\n",
    "                    result.update(fetch_gee_vars(lat, lon, year))\n",
    "                    time.sleep(delay)\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ GEE error (skipping): {e}\")\n",
    "                    result.update({\n",
    "                        \"ndvi_mean_(0â€“1)_(0.25x0.25km)\": None,\n",
    "                        \"human_density_(people/kmÂ²)_(0.1x0.1km)\": None\n",
    "                    })\n",
    "            else:\n",
    "                result.update({\n",
    "                    \"ndvi_mean_(0â€“1)_(0.25x0.25km)\": None,\n",
    "                    \"human_density_(people/kmÂ²)_(0.1x0.1km)\": None\n",
    "                })\n",
    "            \n",
    "            cache[key] = result\n",
    "            \n",
    "            # Save checkpoint at intervals\n",
    "            if (idx + 1) % checkpoint_interval == 0:\n",
    "                print(f\"\\nâœ“ Completed {idx + 1}/{total}. Saving checkpoint...\")\n",
    "                save_cache()\n",
    "                save_checkpoint()\n",
    "                time.sleep(2)  # Brief pause after checkpoint\n",
    "            \n",
    "            # Extra safety: pause every 50 requests\n",
    "            elif (idx + 1) % 50 == 0:\n",
    "                print(f\"\\nâœ“ Completed {idx + 1}/{total}. Pausing 5s...\")\n",
    "                save_cache()  # Save cache at regular intervals too\n",
    "                time.sleep(5)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ Interrupted by user. Saving progress...\")\n",
    "        save_cache()\n",
    "        save_checkpoint()\n",
    "        print(\"âœ“ Progress saved. You can resume by running the same command.\")\n",
    "        raise\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error occurred: {e}\")\n",
    "        print(\"Saving progress before exiting...\")\n",
    "        save_cache()\n",
    "        save_checkpoint()\n",
    "        raise\n",
    "    \n",
    "    # Final save\n",
    "    print(\"\\nðŸ“Š Filling dataframe with cached results...\")\n",
    "    save_cache()\n",
    "    \n",
    "    df = fill_dataframe_from_cache(df, cache, cols, lat_col, lon_col, year_col)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_dataframe_from_cache(df, cache, cols, lat_col, lon_col, year_col):\n",
    "    \"\"\"Helper function to fill dataframe from cache.\"\"\"\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        lat = round(float(row[lat_col]), 3)\n",
    "        lon = round(float(row[lon_col]), 3)\n",
    "        year = int(row[year_col])\n",
    "        \n",
    "        key = (lat, lon, year)\n",
    "        vals = cache.get(key, {})\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in vals:\n",
    "                df.at[i, col] = vals[col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------ 5ï¸âƒ£ EXAMPLE USAGE ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with a small test dataset\n",
    "    test_data = {\n",
    "        'grid_id': ['g_0_321', 'g_0_322', 'g_0_323'],\n",
    "        'year': [2018, 2018, 2018],\n",
    "        'lat_center': [22.15, 22.25, 22.35],\n",
    "        'lon_center': [60.05, 60.05, 60.05]\n",
    "    }\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data)\n",
    "    \n",
    "    init_earth_engine() # Initialize Earth Engine\n",
    "    # Fetch without GEE (if you don't have Earth Engine set up)\n",
    "    df_result = append_covariates(df_test, use_gee=True, requests_per_minute=30)\n",
    "    \n",
    "    print(\"\\nâœ… Results:\")\n",
    "    print(df_result)\n",
    "    \n",
    "    # Save results\n",
    "    df_result.to_csv(os.path.join(base_path,\"climate_data_test.csv\"), index=False)\n",
    "    print(\"\\nðŸ’¾ Saved to climate_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdd392b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# First run (or resume from interruption)\u001b[39;00m\n\u001b[32m      2\u001b[39m df2 = append_covariates(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mdf\u001b[49m,\n\u001b[32m      4\u001b[39m     use_gee=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      5\u001b[39m     requests_per_minute=\u001b[32m30\u001b[39m,\n\u001b[32m      6\u001b[39m     cache_file=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/climate_cache.json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     checkpoint_file=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/climate_checkpoint.csv\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      8\u001b[39m     checkpoint_interval=\u001b[32m100\u001b[39m  \u001b[38;5;66;03m# Save every 100 requests\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Save final results\u001b[39;00m\n\u001b[32m     12\u001b[39m df2.to_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/analysis_panel_causal_covariates.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# First run (or resume from interruption)\n",
    "df2 = append_covariates(\n",
    "    df,\n",
    "    use_gee=True,\n",
    "    requests_per_minute=30,\n",
    "    cache_file=\"data/processed/climate_cache.json\",\n",
    "    checkpoint_file=\"data/processed/climate_checkpoint.csv\", \n",
    "    checkpoint_interval=100  # Save every 100 requests\n",
    ")\n",
    "\n",
    "# Save final results\n",
    "df2.to_csv(\"data/processed/analysis_panel_causal_covariates.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
